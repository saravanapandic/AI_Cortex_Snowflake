[0m01:29:30.634172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71eeaed1ecf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71eeb0b317f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71eeafb270b0>]}


============================== 01:29:30.637540 | e5e3a178-b01d-4636-9983-5ca5c8fb9a89 ==============================
[0m01:29:30.637540 [info ] [MainThread]: Running with dbt=1.10.15
[0m01:29:30.638409 [debug] [MainThread]: running dbt with arguments {'log_path': 'Ai_Cortex/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'log_format': 'default', 'empty': 'None', 'printer_width': '80', 'partial_parse': 'True', 'version_check': 'True', 'fail_fast': 'False', 'profiles_dir': 'Ai_Cortex', 'no_print': 'None', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'static_parser': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'indirect_selection': 'eager'}
[0m01:29:30.648976 [info ] [MainThread]: dbt version: 1.10.15
[0m01:29:30.649560 [info ] [MainThread]: python version: 3.12.1
[0m01:29:30.650097 [info ] [MainThread]: python path: /usr/local/python/3.12.1/bin/python3
[0m01:29:30.650641 [info ] [MainThread]: os info: Linux-6.8.0-1030-azure-x86_64-with-glibc2.39
[0m01:29:31.178463 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m01:29:31.179173 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m01:29:31.179738 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m01:29:31.247497 [info ] [MainThread]: Using profiles dir at Ai_Cortex
[0m01:29:31.248228 [info ] [MainThread]: Using profiles.yml file at Ai_Cortex/profiles.yml
[0m01:29:31.248788 [info ] [MainThread]: Using dbt_project.yml file at Ai_Cortex/dbt_project.yml
[0m01:29:31.249559 [info ] [MainThread]: adapter type: snowflake
[0m01:29:31.250071 [info ] [MainThread]: adapter version: 1.10.3
[0m01:29:31.382436 [info ] [MainThread]: Configuration:
[0m01:29:31.383331 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m01:29:31.384384 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m01:29:31.385256 [info ] [MainThread]: Required dependencies:
[0m01:29:31.385814 [debug] [MainThread]: Executing "git --help"
[0m01:29:31.388482 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m01:29:31.389082 [debug] [MainThread]: STDERR: "b''"
[0m01:29:31.389812 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m01:29:31.390779 [info ] [MainThread]: Connection:
[0m01:29:31.391560 [info ] [MainThread]:   account: GXUGAIL-QU64760
[0m01:29:31.392198 [info ] [MainThread]:   user: saravanapandi
[0m01:29:31.392738 [info ] [MainThread]:   database: ai_cortex
[0m01:29:31.393306 [info ] [MainThread]:   warehouse: compute_wh
[0m01:29:31.393823 [info ] [MainThread]:   role: accountadmin
[0m01:29:31.394362 [info ] [MainThread]:   schema: public
[0m01:29:31.394873 [info ] [MainThread]:   authenticator: None
[0m01:29:31.395488 [info ] [MainThread]:   oauth_client_id: None
[0m01:29:31.396012 [info ] [MainThread]:   query_tag: None
[0m01:29:31.396668 [info ] [MainThread]:   client_session_keep_alive: False
[0m01:29:31.397425 [info ] [MainThread]:   host: None
[0m01:29:31.398157 [info ] [MainThread]:   port: None
[0m01:29:31.398935 [info ] [MainThread]:   proxy_host: None
[0m01:29:31.399877 [info ] [MainThread]:   proxy_port: None
[0m01:29:31.400496 [info ] [MainThread]:   protocol: None
[0m01:29:31.401044 [info ] [MainThread]:   connect_retries: 1
[0m01:29:31.401668 [info ] [MainThread]:   connect_timeout: None
[0m01:29:31.402385 [info ] [MainThread]:   retry_on_database_errors: False
[0m01:29:31.403132 [info ] [MainThread]:   retry_all: False
[0m01:29:31.403879 [info ] [MainThread]:   insecure_mode: False
[0m01:29:31.404614 [info ] [MainThread]:   reuse_connections: True
[0m01:29:31.405183 [info ] [MainThread]:   s3_stage_vpce_dns_name: None
[0m01:29:31.405780 [info ] [MainThread]:   platform_detection_timeout_seconds: 0.0
[0m01:29:31.406565 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m01:29:31.587468 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m01:29:31.636425 [debug] [MainThread]: Using snowflake connection "debug"
[0m01:29:31.637743 [debug] [MainThread]: On debug: select 1 as id
[0m01:29:31.638690 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:29:32.500672 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.862 seconds
[0m01:29:32.504388 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m01:29:32.504998 [info ] [MainThread]: [32mAll checks passed![0m
[0m01:29:32.506272 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.9358131, "process_in_blocks": "0", "process_kernel_time": 0.392411, "process_mem_max_rss": "197516", "process_out_blocks": "32", "process_user_time": 3.733889}
[0m01:29:32.506889 [debug] [MainThread]: Command `dbt debug` succeeded at 01:29:32.506773 after 1.94 seconds
[0m01:29:32.507390 [debug] [MainThread]: Connection 'debug' was left open.
[0m01:29:32.507851 [debug] [MainThread]: On debug: Close
[0m01:29:32.542340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71eeade4bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71eea2accb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71eea2acc3b0>]}
[0m01:29:32.543049 [debug] [MainThread]: Flushing usage events
[0m01:29:33.531715 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:46:00.580272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552f0b5ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c5530558f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552f80a630>]}


============================== 01:46:00.583693 | 3de928f5-fa2a-4497-a82a-0d1460e58f9b ==============================
[0m01:46:00.583693 [info ] [MainThread]: Running with dbt=1.10.15
[0m01:46:00.584532 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'profiles_dir': 'Ai_Cortex', 'indirect_selection': 'eager', 'empty': 'None', 'debug': 'False', 'write_json': 'True', 'no_print': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'partial_parse': 'True', 'use_colors': 'True', 'target_path': 'None', 'warn_error': 'None', 'version_check': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'Ai_Cortex/logs', 'printer_width': '80', 'log_format': 'default', 'log_cache_events': 'False', 'quiet': 'False', 'static_parser': 'True'}
[0m01:46:01.139585 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m01:46:01.140449 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m01:46:01.141176 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m01:46:01.386174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3de928f5-fa2a-4497-a82a-0d1460e58f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c55310ea030>]}
[0m01:46:01.456702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3de928f5-fa2a-4497-a82a-0d1460e58f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552dc0dd90>]}
[0m01:46:01.457662 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m01:46:01.630813 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m01:46:01.631698 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m01:46:01.632311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3de928f5-fa2a-4497-a82a-0d1460e58f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552390c7a0>]}
[0m01:46:03.411099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3de928f5-fa2a-4497-a82a-0d1460e58f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552e9240e0>]}
[0m01:46:03.490980 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m01:46:03.493421 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m01:46:03.503679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3de928f5-fa2a-4497-a82a-0d1460e58f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552368e960>]}
[0m01:46:03.504269 [info ] [MainThread]: Found 2 models, 4 data tests, 506 macros
[0m01:46:03.504851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3de928f5-fa2a-4497-a82a-0d1460e58f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552ea43b30>]}
[0m01:46:03.505612 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m01:46:03.512366 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m01:46:03.513107 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m01:46:03.513895 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:46:04.403141 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  'dict object' has no attribute 'model..my_first_dbt_model'
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>
[0m01:46:04.407153 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 41, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 319, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 870, in __getattr__
    return self._fail_with_undefined_error()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 859, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'dict object' has no attribute 'model..my_first_dbt_model'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  'dict object' has no attribute 'model..my_first_dbt_model'
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>

[0m01:46:04.415265 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m01:46:04.416343 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 3.900192, "process_in_blocks": "4728", "process_kernel_time": 0.444361, "process_mem_max_rss": "200664", "process_out_blocks": "2144", "process_user_time": 5.298535}
[0m01:46:04.416960 [debug] [MainThread]: Command `dbt run-operation` failed at 01:46:04.416835 after 3.90 seconds
[0m01:46:04.417459 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m01:46:04.417909 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m01:46:04.494931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552f0df4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552368f200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c552362d220>]}
[0m01:46:04.495554 [debug] [MainThread]: Flushing usage events
[0m01:46:05.691212 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:47:27.772305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77674beca390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77674ba4d730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77674af30b30>]}


============================== 01:47:27.775811 | 225a3c04-623c-437e-9c3d-558b4310ac31 ==============================
[0m01:47:27.775811 [info ] [MainThread]: Running with dbt=1.10.15
[0m01:47:27.776640 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'fail_fast': 'False', 'profiles_dir': 'Ai_Cortex', 'warn_error': 'None', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'Ai_Cortex/logs', 'version_check': 'True', 'empty': 'None', 'cache_selected_only': 'False', 'partial_parse': 'True', 'quiet': 'False', 'log_format': 'default', 'printer_width': '80', 'introspect': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'target_path': 'None', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True'}
[0m01:47:28.336997 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m01:47:28.337681 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m01:47:28.338271 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m01:47:28.553503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '225a3c04-623c-437e-9c3d-558b4310ac31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77674d0c1e50>]}
[0m01:47:28.627912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '225a3c04-623c-437e-9c3d-558b4310ac31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77673fe97cb0>]}
[0m01:47:28.628935 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m01:47:28.803817 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m01:47:28.910135 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:47:28.910879 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m01:47:28.991432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '225a3c04-623c-437e-9c3d-558b4310ac31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77673fd90170>]}
[0m01:47:29.067425 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m01:47:29.069358 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m01:47:29.081020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '225a3c04-623c-437e-9c3d-558b4310ac31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77673fbae180>]}
[0m01:47:29.081644 [info ] [MainThread]: Found 2 models, 4 data tests, 506 macros
[0m01:47:29.082240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '225a3c04-623c-437e-9c3d-558b4310ac31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77673f93e600>]}
[0m01:47:29.082938 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m01:47:29.091887 [info ] [MainThread]: 
[0m01:47:29.092697 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m01:47:29.093170 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m01:47:29.093622 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:47:29.929977 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  'dict object' has no attribute 'model..my_first_dbt_model'
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>
[0m01:47:29.932609 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 43, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 319, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 870, in __getattr__
    return self._fail_with_undefined_error()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 859, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'dict object' has no attribute 'model..my_first_dbt_model'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  'dict object' has no attribute 'model..my_first_dbt_model'
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>

[0m01:47:29.940901 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m01:47:29.941992 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.2304344, "process_in_blocks": "0", "process_kernel_time": 0.401318, "process_mem_max_rss": "197888", "process_out_blocks": "2144", "process_user_time": 3.929325}
[0m01:47:29.942645 [debug] [MainThread]: Command `dbt run-operation` failed at 01:47:29.942532 after 2.23 seconds
[0m01:47:29.943130 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m01:47:29.943586 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m01:47:29.982704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77674ab501d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77673fbae810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77674ba4cce0>]}
[0m01:47:29.984523 [debug] [MainThread]: Flushing usage events
[0m01:47:31.177945 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:49:10.486357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b4859ddf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b4868000b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b4859dd9a0>]}


============================== 01:49:10.490024 | 393b80ce-c3c0-40cb-bf37-9b68ea8930e8 ==============================
[0m01:49:10.490024 [info ] [MainThread]: Running with dbt=1.10.15
[0m01:49:10.491106 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'debug': 'False', 'log_cache_events': 'False', 'profiles_dir': 'Ai_Cortex', 'use_colors': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'no_print': 'None', 'printer_width': '80', 'empty': 'None', 'quiet': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'static_parser': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'cache_selected_only': 'False', 'introspect': 'True', 'log_path': 'Ai_Cortex/logs'}
[0m01:49:11.013697 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m01:49:11.014359 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m01:49:11.014862 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m01:49:11.214377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '393b80ce-c3c0-40cb-bf37-9b68ea8930e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b4860fa900>]}
[0m01:49:11.284262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '393b80ce-c3c0-40cb-bf37-9b68ea8930e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b47b03f380>]}
[0m01:49:11.285192 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m01:49:11.466939 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m01:49:11.574897 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:49:11.575667 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m01:49:11.656230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '393b80ce-c3c0-40cb-bf37-9b68ea8930e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b47a72cce0>]}
[0m01:49:11.732040 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m01:49:11.734013 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m01:49:11.745677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '393b80ce-c3c0-40cb-bf37-9b68ea8930e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b47a5526f0>]}
[0m01:49:11.746274 [info ] [MainThread]: Found 2 models, 4 data tests, 506 macros
[0m01:49:11.746855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '393b80ce-c3c0-40cb-bf37-9b68ea8930e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b47a566d50>]}
[0m01:49:11.747587 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m01:49:11.757207 [info ] [MainThread]: Ai_Cortex
[0m01:49:11.757957 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
[0m01:49:11.768208 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m01:49:11.769298 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 1.3451493, "process_in_blocks": "0", "process_kernel_time": 0.407843, "process_mem_max_rss": "192084", "process_out_blocks": "2120", "process_user_time": 4.006815}
[0m01:49:11.770021 [debug] [MainThread]: Command `dbt run-operation` succeeded at 01:49:11.769903 after 1.35 seconds
[0m01:49:11.770528 [debug] [MainThread]: Connection 'macro_Ai_Debug' was properly closed.
[0m01:49:11.771024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b486411af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b47a9c11c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b485cf61b0>]}
[0m01:49:11.771549 [debug] [MainThread]: Flushing usage events
[0m01:49:12.954882 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:50:05.968755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc7f9327e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc7d5f1580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc7e5e02c0>]}


============================== 01:50:05.972160 | 1c67d3ec-3405-46bf-9e8e-8295902c3460 ==============================
[0m01:50:05.972160 [info ] [MainThread]: Running with dbt=1.10.15
[0m01:50:05.972942 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'indirect_selection': 'eager', 'static_parser': 'True', 'use_colors': 'True', 'debug': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'printer_width': '80', 'empty': 'None', 'target_path': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'log_path': 'Ai_Cortex/logs', 'log_cache_events': 'False', 'profiles_dir': 'Ai_Cortex', 'cache_selected_only': 'False', 'log_format': 'default', 'introspect': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'partial_parse': 'True'}
[0m01:50:06.596664 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m01:50:06.597328 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m01:50:06.597932 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m01:50:06.801223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c67d3ec-3405-46bf-9e8e-8295902c3460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc727deea0>]}
[0m01:50:06.887440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c67d3ec-3405-46bf-9e8e-8295902c3460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc72f55ee0>]}
[0m01:50:06.888454 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m01:50:07.074245 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m01:50:07.180194 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:50:07.180941 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m01:50:07.261192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c67d3ec-3405-46bf-9e8e-8295902c3460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc720af500>]}
[0m01:50:07.336494 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m01:50:07.338373 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m01:50:07.349825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c67d3ec-3405-46bf-9e8e-8295902c3460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc721d9940>]}
[0m01:50:07.350447 [info ] [MainThread]: Found 2 models, 4 data tests, 506 macros
[0m01:50:07.351015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c67d3ec-3405-46bf-9e8e-8295902c3460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc720c76b0>]}
[0m01:50:07.351758 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m01:50:07.360874 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
[0m01:50:07.368005 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m01:50:07.369505 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 1.4616349, "process_in_blocks": "0", "process_kernel_time": 0.447978, "process_mem_max_rss": "191924", "process_out_blocks": "2120", "process_user_time": 3.915334}
[0m01:50:07.370582 [debug] [MainThread]: Command `dbt run-operation` succeeded at 01:50:07.370452 after 1.46 seconds
[0m01:50:07.371043 [debug] [MainThread]: Connection 'macro_Ai_Debug' was properly closed.
[0m01:50:07.371572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc7dc0f4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc7218cc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74fc724b0e90>]}
[0m01:50:07.372068 [debug] [MainThread]: Flushing usage events
[0m01:50:08.382319 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:03:01.064983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1c8e4a330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1c89f9e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1c8530680>]}


============================== 02:03:01.068417 | a3d5aa33-51a4-43e6-865b-dcb6b2ae5cc2 ==============================
[0m02:03:01.068417 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:03:01.069256 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'version_check': 'True', 'no_print': 'None', 'empty': 'None', 'partial_parse': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'profiles_dir': 'Ai_Cortex', 'static_parser': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'log_path': 'Ai_Cortex/logs', 'warn_error': 'None', 'log_format': 'default', 'fail_fast': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'printer_width': '80', 'write_json': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m02:03:01.625189 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:03:01.625833 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:03:01.626616 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:03:01.853622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3d5aa33-51a4-43e6-865b-dcb6b2ae5cc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1bd3fb0b0>]}
[0m02:03:01.931962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3d5aa33-51a4-43e6-865b-dcb6b2ae5cc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1c8c8dd90>]}
[0m02:03:01.932979 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:03:02.111419 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:03:02.217305 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m02:03:02.217982 [debug] [MainThread]: Partial parsing: added file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:03:02.218568 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m02:03:02.223041 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two macros named "Ai_Debug" in the project "Ai_Cortex".
   To fix this error, rename or remove one of the following macros:
      - macros/Ai_Debug.sql
      - macros/Prompt/Ai_validate.sql
[0m02:03:02.224283 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.2192479, "process_in_blocks": "0", "process_kernel_time": 0.399608, "process_mem_max_rss": "190568", "process_out_blocks": "16", "process_user_time": 3.699114}
[0m02:03:02.225049 [debug] [MainThread]: Command `dbt run-operation` failed at 02:03:02.224934 after 1.22 seconds
[0m02:03:02.225578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1c86e2270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1bcfaf080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73e1bcf87110>]}
[0m02:03:02.226089 [debug] [MainThread]: Flushing usage events
[0m02:03:03.389935 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:03:24.309381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e6839701850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e683998fe00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e6839459820>]}


============================== 02:03:24.312878 | cef5e439-2e8d-4650-af97-2c83aa393e2b ==============================
[0m02:03:24.312878 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:03:24.313713 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'profiles_dir': 'Ai_Cortex', 'write_json': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'fail_fast': 'False', 'debug': 'False', 'partial_parse': 'True', 'quiet': 'False', 'no_print': 'None', 'log_path': 'Ai_Cortex/logs', 'log_format': 'default', 'cache_selected_only': 'False', 'printer_width': '80', 'empty': 'None', 'warn_error': 'None'}
[0m02:03:24.877412 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:03:24.878056 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:03:24.878657 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:03:25.096970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cef5e439-2e8d-4650-af97-2c83aa393e2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682df6ac60>]}
[0m02:03:25.167679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cef5e439-2e8d-4650-af97-2c83aa393e2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e683948ae70>]}
[0m02:03:25.168667 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:03:25.351788 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:03:25.461005 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m02:03:25.461727 [debug] [MainThread]: Partial parsing: added file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:03:25.462356 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m02:03:25.551599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cef5e439-2e8d-4650-af97-2c83aa393e2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682db63110>]}
[0m02:03:25.640854 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:03:25.642869 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:03:25.652942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cef5e439-2e8d-4650-af97-2c83aa393e2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682d8ff590>]}
[0m02:03:25.653578 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:03:25.654184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cef5e439-2e8d-4650-af97-2c83aa393e2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682d8f94c0>]}
[0m02:03:25.654915 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:03:25.664716 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
[0m02:03:25.665568 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m02:03:25.666031 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m02:03:25.666534 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:26.441717 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  'cortex_ai' is undefined
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>
[0m02:03:26.444374 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 60, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 319, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 870, in __getattr__
    return self._fail_with_undefined_error()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 859, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'cortex_ai' is undefined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  'cortex_ai' is undefined
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>

[0m02:03:26.452563 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:03:26.453638 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.2059705, "process_in_blocks": "0", "process_kernel_time": 0.428047, "process_mem_max_rss": "198244", "process_out_blocks": "2160", "process_user_time": 4.043999}
[0m02:03:26.454277 [debug] [MainThread]: Command `dbt run-operation` failed at 02:03:26.454163 after 2.21 seconds
[0m02:03:26.454751 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:03:26.455215 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:03:26.743676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e68392bb950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682dfb8170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682db7fd70>]}
[0m02:03:26.744377 [debug] [MainThread]: Flushing usage events
[0m02:03:27.788948 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:03:47.157073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557d14603b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557d3c5e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557d3a39970>]}


============================== 02:03:47.160571 | 90a23b3d-886a-45ea-aa16-8b882f6459be ==============================
[0m02:03:47.160571 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:03:47.161426 [debug] [MainThread]: running dbt with arguments {'log_path': 'Ai_Cortex/logs', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'empty': 'None', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'introspect': 'True', 'profiles_dir': 'Ai_Cortex', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'write_json': 'True', 'target_path': 'None', 'static_parser': 'True', 'log_format': 'default'}
[0m02:03:47.734821 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:03:47.735503 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:03:47.736096 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:03:47.937776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90a23b3d-886a-45ea-aa16-8b882f6459be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557c634fb30>]}
[0m02:03:48.007911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90a23b3d-886a-45ea-aa16-8b882f6459be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557d389bb60>]}
[0m02:03:48.009243 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:03:48.193471 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:03:48.304213 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:03:48.304958 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m02:03:48.385604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90a23b3d-886a-45ea-aa16-8b882f6459be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557c5f6a9c0>]}
[0m02:03:48.461089 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:03:48.463491 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:03:48.475103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90a23b3d-886a-45ea-aa16-8b882f6459be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557c5f6aa50>]}
[0m02:03:48.475741 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:03:48.476357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90a23b3d-886a-45ea-aa16-8b882f6459be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557c5f3f470>]}
[0m02:03:48.477072 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:03:48.486722 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m02:03:48.487225 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m02:03:48.487675 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:49.267110 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  'cortex_ai' is undefined
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>
[0m02:03:49.269788 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 57, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 319, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 870, in __getattr__
    return self._fail_with_undefined_error()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 859, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'cortex_ai' is undefined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  'cortex_ai' is undefined
  
  > in macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>

[0m02:03:49.278371 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:03:49.279533 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.1835184, "process_in_blocks": "0", "process_kernel_time": 0.397038, "process_mem_max_rss": "197764", "process_out_blocks": "2168", "process_user_time": 4.036868}
[0m02:03:49.280180 [debug] [MainThread]: Command `dbt run-operation` failed at 02:03:49.280029 after 2.18 seconds
[0m02:03:49.280675 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:03:49.281146 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:03:49.320525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557d198e240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557c5f6b830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7557c66d1a00>]}
[0m02:03:49.321084 [debug] [MainThread]: Flushing usage events
[0m02:03:50.332516 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:10:26.832510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151c9c45460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151ca2a23f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151c95f7440>]}


============================== 02:10:26.836016 | 2c7ac7a7-e769-4132-a796-b57ff8f50365 ==============================
[0m02:10:26.836016 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:10:26.836811 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'printer_width': '80', 'quiet': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': 'Ai_Cortex/logs', 'version_check': 'True', 'static_parser': 'True', 'debug': 'False', 'log_cache_events': 'False', 'empty': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'log_format': 'default', 'fail_fast': 'False', 'introspect': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'Ai_Cortex', 'no_print': 'None'}
[0m02:10:27.393131 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:10:27.393766 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:10:27.394354 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:10:27.595347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c7ac7a7-e769-4132-a796-b57ff8f50365', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151be4b2210>]}
[0m02:10:27.692874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c7ac7a7-e769-4132-a796-b57ff8f50365', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151ca1665a0>]}
[0m02:10:27.693878 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:10:27.873035 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:10:27.996483 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:10:27.997312 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:10:27.997830 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Ai_Debug.sql
[0m02:10:28.107698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c7ac7a7-e769-4132-a796-b57ff8f50365', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151be01b7a0>]}
[0m02:10:28.185873 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:10:28.187811 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:10:28.198028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c7ac7a7-e769-4132-a796-b57ff8f50365', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151be0ac200>]}
[0m02:10:28.198678 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:10:28.199287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c7ac7a7-e769-4132-a796-b57ff8f50365', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151be1e5fa0>]}
[0m02:10:28.200018 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:10:28.255662 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:10:28.256283 [debug] [MainThread]: On macro_Ai_Debug: SET your_sql = $$
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:10:28.256757 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:10:29.163909 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01c092e2-0001-6bc5-0000-000ccdbad289
[0m02:10:29.164559 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002126 (22005): Assignment to 'YOUR_SQL' not done because value exceeds size limit for variables. Its size is 475; the limit is 256 (internal storage size in bytes).
[0m02:10:29.165309 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m02:10:29.165778 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m02:10:29.166411 [error] [MainThread]: Encountered an error while running operation: Database Error
  002126 (22005): Assignment to 'YOUR_SQL' not done because value exceeds size limit for variables. Its size is 475; the limit is 256 (internal storage size in bytes).
[0m02:10:29.170442 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 335, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 148, in add_query
    _execute_query_with_retry(
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 97, in _execute_query_with_retry
    cursor.execute(sql, bindings)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1134, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002126 (22005): Assignment to 'YOUR_SQL' not done because value exceeds size limit for variables. Its size is 475; the limit is 256 (internal storage size in bytes).

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 57, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 60, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 33, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/record.py", line 538, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 461, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 536, in execute
    _, cursor = self.add_query(sql, auto_begin)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 573, in add_query
    connection, cursor = self._add_standard_queries(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 632, in _add_standard_queries
    connection, cursor = self.add_standard_query(query, **kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 547, in add_standard_query
    return super().add_query(self._add_query_comment(sql), **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 131, in add_query
    with self.exception_handler(sql):
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 361, in exception_handler
    raise DbtDatabaseError(msg)
dbt_common.exceptions.base.DbtDatabaseError: Database Error
  002126 (22005): Assignment to 'YOUR_SQL' not done because value exceeds size limit for variables. Its size is 475; the limit is 256 (internal storage size in bytes).

[0m02:10:29.179205 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:10:29.180287 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.4087894, "process_in_blocks": "200", "process_kernel_time": 0.424601, "process_mem_max_rss": "202060", "process_out_blocks": "2184", "process_user_time": 4.199171}
[0m02:10:29.180933 [debug] [MainThread]: Command `dbt run-operation` failed at 02:10:29.180787 after 2.41 seconds
[0m02:10:29.181449 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:10:29.181894 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:10:29.229979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151c9b64ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151bdd30680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7151bdd30050>]}
[0m02:10:29.231019 [debug] [MainThread]: Flushing usage events
[0m02:10:30.439630 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:12:30.815353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e96109ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e9655d340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e9610ad50>]}


============================== 02:12:30.818790 | 645ee7da-1f09-4073-9bcc-4486e99e4672 ==============================
[0m02:12:30.818790 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:12:30.819598 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'debug': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'log_format': 'default', 'indirect_selection': 'eager', 'target_path': 'None', 'log_path': 'Ai_Cortex/logs', 'use_colors': 'True', 'empty': 'None', 'version_check': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'profiles_dir': 'Ai_Cortex', 'no_print': 'None', 'quiet': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'fail_fast': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m02:12:31.366113 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:12:31.366766 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:12:31.367286 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:12:31.570602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '645ee7da-1f09-4073-9bcc-4486e99e4672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e8bd67830>]}
[0m02:12:31.641328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '645ee7da-1f09-4073-9bcc-4486e99e4672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e8d1d1040>]}
[0m02:12:31.642353 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:12:31.818779 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:12:31.924084 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:12:31.924875 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:12:32.016272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '645ee7da-1f09-4073-9bcc-4486e99e4672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e8a9ce5d0>]}
[0m02:12:32.094168 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:12:32.096087 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:12:32.105977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '645ee7da-1f09-4073-9bcc-4486e99e4672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e8a576840>]}
[0m02:12:32.106601 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:12:32.107196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '645ee7da-1f09-4073-9bcc-4486e99e4672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e8a58abd0>]}
[0m02:12:32.107908 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:12:32.161884 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:12:32.162612 [debug] [MainThread]: On macro_Ai_Debug: SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => '
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
' || model_code || '
$$
'
      ) AS result
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:12:32.163193 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:12:33.243738 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01c092e4-0001-6bdd-000c-cdba000101ba
[0m02:12:33.244367 [debug] [MainThread]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 71 at position 5
invalid identifier 'MODEL_CODE'
[0m02:12:33.245109 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m02:12:33.245608 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m02:12:33.246223 [error] [MainThread]: Encountered an error while running operation: Database Error
  000904 (42000): SQL compilation error: error line 71 at position 5
  invalid identifier 'MODEL_CODE'
[0m02:12:33.251322 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 335, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 148, in add_query
    _execute_query_with_retry(
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 97, in _execute_query_with_retry
    cursor.execute(sql, bindings)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1134, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 71 at position 5
invalid identifier 'MODEL_CODE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 57, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 57, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 33, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/record.py", line 538, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 461, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 536, in execute
    _, cursor = self.add_query(sql, auto_begin)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 573, in add_query
    connection, cursor = self._add_standard_queries(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 632, in _add_standard_queries
    connection, cursor = self.add_standard_query(query, **kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 547, in add_standard_query
    return super().add_query(self._add_query_comment(sql), **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 131, in add_query
    with self.exception_handler(sql):
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 361, in exception_handler
    raise DbtDatabaseError(msg)
dbt_common.exceptions.base.DbtDatabaseError: Database Error
  000904 (42000): SQL compilation error: error line 71 at position 5
  invalid identifier 'MODEL_CODE'

[0m02:12:33.259757 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:12:33.260811 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.5069273, "process_in_blocks": "0", "process_kernel_time": 0.422382, "process_mem_max_rss": "202104", "process_out_blocks": "2192", "process_user_time": 3.964201}
[0m02:12:33.261478 [debug] [MainThread]: Command `dbt run-operation` failed at 02:12:33.261363 after 2.51 seconds
[0m02:12:33.261947 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:12:33.262414 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:12:33.298364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e95aca240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e8a29ce30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x733e96664470>]}
[0m02:12:33.299329 [debug] [MainThread]: Flushing usage events
[0m02:12:34.406732 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:13:16.791385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x758965bae4b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x758964e90770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x758964de81a0>]}


============================== 02:13:16.794848 | 317950e5-e5a3-4a64-8d48-3d8b04d16f81 ==============================
[0m02:13:16.794848 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:13:16.795663 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'empty': 'None', 'static_parser': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'warn_error': 'None', 'quiet': 'False', 'debug': 'False', 'printer_width': '80', 'log_path': 'Ai_Cortex/logs', 'profiles_dir': 'Ai_Cortex'}
[0m02:13:17.455998 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:13:17.456711 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:13:17.457262 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:13:17.672103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '317950e5-e5a3-4a64-8d48-3d8b04d16f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x758965a9cb90>]}
[0m02:13:17.753846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '317950e5-e5a3-4a64-8d48-3d8b04d16f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75895a195880>]}
[0m02:13:17.755251 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:13:17.984423 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:13:18.112737 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:13:18.113927 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:13:18.201093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '317950e5-e5a3-4a64-8d48-3d8b04d16f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75895a194920>]}
[0m02:13:18.280728 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:13:18.283362 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:13:18.294323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '317950e5-e5a3-4a64-8d48-3d8b04d16f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x758959be1760>]}
[0m02:13:18.294930 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:13:18.295548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '317950e5-e5a3-4a64-8d48-3d8b04d16f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75896680c2c0>]}
[0m02:13:18.296294 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:13:18.364229 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:13:18.365063 [debug] [MainThread]: On macro_Ai_Debug: SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => '
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 {model_code}
$$
'
      ) AS result
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:13:18.365673 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:13:24.421671 [debug] [MainThread]: SQL status: SUCCESS 1 in 6.056 seconds
[0m02:13:24.423936 [info ] [MainThread]: "I don't see any model code provided to validate and correct. Please provide the dbt model code you'd like me to analyze. I'll then:\n\n1. Validate the SQL parts while preserving all Jinja/dbt constructs\n2. Canonicalize SQL keywords to uppercase\n3. Make safe corrections if needed\n4. Return a single-line JSON with the result, error reason if any, and correction status\n\nThe response will follow the exact format:\n{\"sql\":\"<code>\",\"error_reason\":\"<reason>\",\"able_correct\":<0|1>}\n\nPlease share the model code you'd like me to process."
[0m02:13:24.433497 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:13:24.434790 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 7.720321, "process_in_blocks": "408", "process_kernel_time": 0.469373, "process_mem_max_rss": "201792", "process_out_blocks": "2168", "process_user_time": 4.155894}
[0m02:13:24.435499 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:13:24.435379 after 7.72 seconds
[0m02:13:24.435985 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:13:24.436482 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:13:24.468724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x758959be0b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75895964c080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75895964d070>]}
[0m02:13:24.469644 [debug] [MainThread]: Flushing usage events
[0m02:13:25.286527 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:15:11.508618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c769582ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c768c087a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c769d5cd70>]}


============================== 02:15:11.512179 | 57d36c00-394c-4ac7-9ac5-fc907affb05f ==============================
[0m02:15:11.512179 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:15:11.512952 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'use_colors': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'indirect_selection': 'eager', 'log_path': 'Ai_Cortex/logs', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'printer_width': '80', 'quiet': 'False', 'write_json': 'True', 'target_path': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'cache_selected_only': 'False', 'empty': 'None', 'no_print': 'None', 'profiles_dir': 'Ai_Cortex', 'version_check': 'True', 'static_parser': 'True', 'log_cache_events': 'False'}
[0m02:15:12.076307 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:15:12.076950 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:15:12.077551 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:15:12.282617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '57d36c00-394c-4ac7-9ac5-fc907affb05f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c75d3c3c50>]}
[0m02:15:12.353939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '57d36c00-394c-4ac7-9ac5-fc907affb05f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c768bcd040>]}
[0m02:15:12.354944 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:15:12.527898 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:15:12.632690 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:15:12.633482 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:15:12.718777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57d36c00-394c-4ac7-9ac5-fc907affb05f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c75d282f60>]}
[0m02:15:12.795596 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:15:12.798312 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:15:12.808501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57d36c00-394c-4ac7-9ac5-fc907affb05f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c75d003560>]}
[0m02:15:12.809079 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:15:12.809701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57d36c00-394c-4ac7-9ac5-fc907affb05f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c75d0129c0>]}
[0m02:15:12.810433 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:15:12.825781 [info ] [MainThread]: 
    

      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => '
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$
'
      ) AS result;
    
[0m02:15:12.866192 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:15:12.866837 [debug] [MainThread]: On macro_Ai_Debug: SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => '
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$
'
      ) AS result
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:15:12.867429 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:15:14.365793 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01c092e7-0001-6bdd-000c-cdba000101c2
[0m02:15:14.366416 [debug] [MainThread]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 79 at position 24 unexpected 'table'.
[0m02:15:14.367177 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m02:15:14.367638 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m02:15:14.368271 [error] [MainThread]: Encountered an error while running operation: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 79 at position 24 unexpected 'table'.
[0m02:15:14.372333 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 335, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 148, in add_query
    _execute_query_with_retry(
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 97, in _execute_query_with_retry
    cursor.execute(sql, bindings)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1134, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 79 at position 24 unexpected 'table'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 57, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 61, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 33, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/record.py", line 538, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 461, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 536, in execute
    _, cursor = self.add_query(sql, auto_begin)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 573, in add_query
    connection, cursor = self._add_standard_queries(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 632, in _add_standard_queries
    connection, cursor = self.add_standard_query(query, **kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 547, in add_standard_query
    return super().add_query(self._add_query_comment(sql), **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 131, in add_query
    with self.exception_handler(sql):
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/snowflake/connections.py", line 361, in exception_handler
    raise DbtDatabaseError(msg)
dbt_common.exceptions.base.DbtDatabaseError: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 79 at position 24 unexpected 'table'.

[0m02:15:14.380973 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:15:14.382067 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.9385316, "process_in_blocks": "0", "process_kernel_time": 0.438011, "process_mem_max_rss": "202176", "process_out_blocks": "2192", "process_user_time": 4.142733}
[0m02:15:14.382738 [debug] [MainThread]: Command `dbt run-operation` failed at 02:15:14.382623 after 2.94 seconds
[0m02:15:14.383227 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:15:14.383676 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:15:14.430152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c7691030e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c769100290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c75d012210>]}
[0m02:15:14.430803 [debug] [MainThread]: Flushing usage events
[0m02:15:15.358835 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:46.761697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0b1a12000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0b10f03e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0b1a11d90>]}


============================== 02:22:46.765429 | 333e116a-7676-4487-853b-bb5ae8a74a7d ==============================
[0m02:22:46.765429 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:22:46.766324 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'profiles_dir': 'Ai_Cortex', 'static_parser': 'True', 'empty': 'None', 'no_print': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'use_colors': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'debug': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'warn_error': 'None', 'write_json': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'target_path': 'None', 'cache_selected_only': 'False', 'log_path': 'Ai_Cortex/logs', 'printer_width': '80'}
[0m02:22:47.323456 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:22:47.324099 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:22:47.324703 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:22:47.525512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '333e116a-7676-4487-853b-bb5ae8a74a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0b32dd670>]}
[0m02:22:47.595941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '333e116a-7676-4487-853b-bb5ae8a74a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0a5e3b260>]}
[0m02:22:47.596966 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:22:47.781325 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:22:47.887024 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:22:47.887875 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:22:47.974345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '333e116a-7676-4487-853b-bb5ae8a74a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0a5cd0bf0>]}
[0m02:22:48.053631 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:22:48.055847 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:22:48.066238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '333e116a-7676-4487-853b-bb5ae8a74a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0a59afe90>]}
[0m02:22:48.066823 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:22:48.067419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '333e116a-7676-4487-853b-bb5ae8a74a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0a5e3b9b0>]}
[0m02:22:48.068160 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:22:48.083794 [info ] [MainThread]: 
    

      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result;
    
[0m02:22:48.126075 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:22:48.126809 [debug] [MainThread]: On macro_Ai_Debug: SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:22:48.127405 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:22:52.381882 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.254 seconds
[0m02:22:52.383620 [info ] [MainThread]: "{\"sql\":\"/*\\n    Welcome to your first dbt model!\\n    Did you know that you can also configure models directly within SQL files?\\n    This will override configurations stated in dbt_project.yml\\n\\n    Try changing \\\"table\\\" to \\\"view\\\" below\\n*/\\n\\n{{ config(materialized='table') }}\\n\\nWITH source_data AS (\\n\\n    SELECT 1 AS id\\n    UNION ALL\\n    SELECT null AS id\\n\\n)\\n\\nSELECT *\\nFROM source_data;\\n\\n/*\\n    Uncomment the line below to remove records with null `id` values\\n*/\\n\\n-- where id is not null\\n\",\"error_reason\":\"\",\"able_correct\":1}"
[0m02:22:52.391322 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:22:52.392797 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 5.693087, "process_in_blocks": "0", "process_kernel_time": 0.442013, "process_mem_max_rss": "202352", "process_out_blocks": "2176", "process_user_time": 4.16329}
[0m02:22:52.393434 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:22:52.393321 after 5.69 seconds
[0m02:22:52.393900 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:22:52.394384 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:22:52.431326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0b0cff530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0a58d2240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a0a56dec60>]}
[0m02:22:52.432108 [debug] [MainThread]: Flushing usage events
[0m02:22:53.530646 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:28:09.651073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7946429e5df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794644a44170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7946422af170>]}


============================== 02:28:09.654629 | ff3635ea-0bb8-4d04-b4d3-89f112f186e9 ==============================
[0m02:28:09.654629 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:28:09.655490 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_format': 'default', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'profiles_dir': 'Ai_Cortex', 'log_path': 'Ai_Cortex/logs', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'version_check': 'True', 'debug': 'False', 'empty': 'None', 'partial_parse': 'True', 'introspect': 'True', 'fail_fast': 'False', 'quiet': 'False', 'use_colors': 'True', 'no_print': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}'}
[0m02:28:10.214737 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:28:10.215396 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:28:10.215977 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:28:10.417435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff3635ea-0bb8-4d04-b4d3-89f112f186e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794637a339b0>]}
[0m02:28:10.489613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff3635ea-0bb8-4d04-b4d3-89f112f186e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794637cdd190>]}
[0m02:28:10.490630 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:28:10.729152 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:28:10.887213 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:28:10.888059 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:28:10.888716 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/example/my_first_dbt_model.sql
[0m02:28:11.508041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff3635ea-0bb8-4d04-b4d3-89f112f186e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794636fd5340>]}
[0m02:28:11.579986 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:28:11.582605 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:28:11.592860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff3635ea-0bb8-4d04-b4d3-89f112f186e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794636f3ffe0>]}
[0m02:28:11.593484 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:28:11.594112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff3635ea-0bb8-4d04-b4d3-89f112f186e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79463704c770>]}
[0m02:28:11.594831 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:28:11.608897 [info ] [MainThread]: 
    
with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main;
    
[0m02:28:11.649540 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:28:11.650399 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:28:11.651379 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:28:16.494648 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.843 seconds
[0m02:28:16.500903 [info ] [MainThread]: "/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing \"table\" to \"view\" below\n*/\n\n{{ config(materialized='table') }}\n\nWITH source_data AS (\n\n    SELECT 1 AS id\n    UNION ALL\n    SELECT null AS id\n\n)\n\nSELECT *\nFROM source_data;\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null\n"
[0m02:28:16.514210 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:28:16.515294 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.953273, "process_in_blocks": "0", "process_kernel_time": 0.484618, "process_mem_max_rss": "204588", "process_out_blocks": "2184", "process_user_time": 4.701893}
[0m02:28:16.515898 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:28:16.515785 after 6.95 seconds
[0m02:28:16.516393 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:28:16.516858 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:28:16.555422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794636f3caa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794636418470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x794641dc03b0>]}
[0m02:28:16.556009 [debug] [MainThread]: Flushing usage events
[0m02:28:17.581469 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:28:56.489224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa9b3b18e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa9b385190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa9b385640>]}


============================== 02:28:56.492691 | 19f8c493-8ef7-452d-a511-99178238d52c ==============================
[0m02:28:56.492691 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:28:56.493517 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'debug': 'False', 'target_path': 'None', 'empty': 'None', 'static_parser': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'write_json': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'profiles_dir': 'Ai_Cortex', 'cache_selected_only': 'False', 'version_check': 'True', 'warn_error': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'quiet': 'False', 'indirect_selection': 'eager', 'log_format': 'default', 'use_colors': 'True', 'log_path': 'Ai_Cortex/logs', 'send_anonymous_usage_stats': 'True'}
[0m02:28:57.077443 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:28:57.078105 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:28:57.078711 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:28:57.279842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '19f8c493-8ef7-452d-a511-99178238d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa8fb25160>]}
[0m02:28:57.350632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '19f8c493-8ef7-452d-a511-99178238d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa901cff20>]}
[0m02:28:57.351579 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:28:57.534695 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:28:57.644956 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:28:57.645761 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:28:57.742610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19f8c493-8ef7-452d-a511-99178238d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa8f83c950>]}
[0m02:28:57.820153 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:28:57.822055 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:28:57.832073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19f8c493-8ef7-452d-a511-99178238d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa8f65e450>]}
[0m02:28:57.832686 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:28:57.833281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19f8c493-8ef7-452d-a511-99178238d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa8f633410>]}
[0m02:28:57.834000 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:28:57.890216 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:28:57.890978 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:28:57.891582 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:29:02.447490 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.556 seconds
[0m02:29:02.449433 [info ] [MainThread]: "/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing \"table\" to \"view\" below\n*/\n\n{{ config(materialized='table') }}\n\nWITH source_data AS (\n\n    SELECT 1 AS id\n    UNION ALL\n    SELECT null AS id\n\n)\n\nSELECT *\nFROM source_data;\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null\n"
[0m02:29:02.457096 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:29:02.458553 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.03468, "process_in_blocks": "0", "process_kernel_time": 0.478701, "process_mem_max_rss": "201988", "process_out_blocks": "2176", "process_user_time": 4.011118}
[0m02:29:02.459219 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:29:02.459046 after 6.04 seconds
[0m02:29:02.459684 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:29:02.460160 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:29:02.507759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa9abab800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa8f633c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76fa8f350470>]}
[0m02:29:02.508325 [debug] [MainThread]: Flushing usage events
[0m02:29:03.517037 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:34:23.654398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff610757230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60eef3b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60f0acbf0>]}


============================== 02:34:23.657830 | 91ca2fe0-8380-4714-9bd2-85c83427443c ==============================
[0m02:34:23.657830 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:34:23.658632 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'quiet': 'False', 'empty': 'None', 'static_parser': 'True', 'version_check': 'True', 'partial_parse': 'True', 'printer_width': '80', 'profiles_dir': 'Ai_Cortex', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'Ai_Cortex/logs'}
[0m02:34:24.189014 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:34:24.189659 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:34:24.190189 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:34:24.389910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '91ca2fe0-8380-4714-9bd2-85c83427443c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60f407680>]}
[0m02:34:24.460458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '91ca2fe0-8380-4714-9bd2-85c83427443c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6039df290>]}
[0m02:34:24.461437 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:34:24.637283 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:34:24.743763 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:34:24.744599 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:34:24.831906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '91ca2fe0-8380-4714-9bd2-85c83427443c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff603156270>]}
[0m02:34:24.910227 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:34:24.912519 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:34:24.926821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '91ca2fe0-8380-4714-9bd2-85c83427443c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff603156120>]}
[0m02:34:24.927782 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:34:24.928888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '91ca2fe0-8380-4714-9bd2-85c83427443c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60316a330>]}
[0m02:34:24.930066 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:34:25.002581 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:34:25.003308 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:34:25.003890 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:34:30.095337 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.091 seconds
[0m02:34:30.097285 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Debug
[0m02:34:30.097931 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m02:34:30.098550 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  agate.mapped_sequence.MappedSequence object has no element 1
  
  > in macro Ai_Validate_Model (macros/Prompt/Ai_validate.sql)
  > called by macro default__Ai_Debug (macros/Ai_Debug.sql)
  > called by macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>
[0m02:34:30.101334 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 68, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 293, in getitem
    return obj[argument]
           ~~~^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 859, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: agate.mapped_sequence.MappedSequence object has no element 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 57, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 21, in macro
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  agate.mapped_sequence.MappedSequence object has no element 1
  
  > in macro Ai_Validate_Model (macros/Prompt/Ai_validate.sql)
  > called by macro default__Ai_Debug (macros/Ai_Debug.sql)
  > called by macro Ai_Debug (macros/Ai_Debug.sql)
  > called by <Unknown>

[0m02:34:30.109541 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:34:30.110586 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 6.517108, "process_in_blocks": "0", "process_kernel_time": 0.422404, "process_mem_max_rss": "202028", "process_out_blocks": "2192", "process_user_time": 3.948432}
[0m02:34:30.111226 [debug] [MainThread]: Command `dbt run-operation` failed at 02:34:30.111078 after 6.52 seconds
[0m02:34:30.111690 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:34:30.112142 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:34:30.247154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60ee36660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff603156ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff602e54590>]}
[0m02:34:30.247844 [debug] [MainThread]: Flushing usage events
[0m02:34:31.334417 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:35:56.272265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd48a1405f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd48bbab6e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd48a143680>]}


============================== 02:35:56.275631 | eeb65a9c-7fbf-454e-bc66-44a1170f6c70 ==============================
[0m02:35:56.275631 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:35:56.276452 [debug] [MainThread]: running dbt with arguments {'log_path': 'Ai_Cortex/logs', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'log_cache_events': 'False', 'version_check': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'empty': 'None', 'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'profiles_dir': 'Ai_Cortex', 'target_path': 'None', 'indirect_selection': 'eager', 'printer_width': '80'}
[0m02:35:56.838335 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:35:56.838968 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:35:56.839565 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:35:57.038776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eeb65a9c-7fbf-454e-bc66-44a1170f6c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd488a46e70>]}
[0m02:35:57.107837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eeb65a9c-7fbf-454e-bc66-44a1170f6c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd47ffb0800>]}
[0m02:35:57.108794 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:35:57.284092 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:35:57.393491 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:35:57.394294 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:35:57.481978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eeb65a9c-7fbf-454e-bc66-44a1170f6c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd47e5141d0>]}
[0m02:35:57.557956 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:35:57.560639 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:35:57.571470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eeb65a9c-7fbf-454e-bc66-44a1170f6c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd47e3422d0>]}
[0m02:35:57.572065 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:35:57.572677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eeb65a9c-7fbf-454e-bc66-44a1170f6c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd47e7f2990>]}
[0m02:35:57.573420 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:35:57.628843 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:35:57.629622 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:35:57.630226 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:36:02.646488 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.016 seconds
[0m02:36:02.648285 [info ] [MainThread]: "/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing \"table\" to \"view\" below\n*/\n\n{{ config(materialized='table') }}\n\nWITH source_data AS (\n\n    SELECT 1 AS id\n    UNION ALL\n    SELECT null AS id\n\n)\n\nSELECT *\nFROM source_data;\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null\n"
[0m02:36:02.655918 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:36:02.657597 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.445817, "process_in_blocks": "0", "process_kernel_time": 0.448602, "process_mem_max_rss": "201968", "process_out_blocks": "2176", "process_user_time": 3.990673}
[0m02:36:02.658250 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:36:02.658097 after 6.45 seconds
[0m02:36:02.658723 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:36:02.659191 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:36:02.700441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd489a6a7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd47e342cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bd47e070ce0>]}
[0m02:36:02.701370 [debug] [MainThread]: Flushing usage events
[0m02:36:03.758325 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:36:24.140935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a14f36180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a14f36de0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a13ee4bf0>]}


============================== 02:36:24.144501 | 90770db1-f301-4196-a44c-8609f216ca02 ==============================
[0m02:36:24.144501 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:36:24.145336 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'indirect_selection': 'eager', 'profiles_dir': 'Ai_Cortex', 'use_colors': 'True', 'debug': 'False', 'log_format': 'default', 'introspect': 'True', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'no_print': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'write_json': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'version_check': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'log_path': 'Ai_Cortex/logs', 'printer_width': '80', 'partial_parse': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None'}
[0m02:36:24.677877 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:36:24.678555 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:36:24.679063 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:36:24.896529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90770db1-f301-4196-a44c-8609f216ca02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a07ee3a40>]}
[0m02:36:24.972883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90770db1-f301-4196-a44c-8609f216ca02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a12bd88f0>]}
[0m02:36:24.973913 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:36:25.154605 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:36:25.304162 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:36:25.305009 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:36:25.406869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90770db1-f301-4196-a44c-8609f216ca02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a078fe5a0>]}
[0m02:36:25.496470 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:36:25.499338 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:36:25.514199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90770db1-f301-4196-a44c-8609f216ca02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a07947230>]}
[0m02:36:25.515080 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:36:25.516546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90770db1-f301-4196-a44c-8609f216ca02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a0795a570>]}
[0m02:36:25.517596 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:36:25.576332 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:36:25.577089 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:36:25.577697 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:36:29.993267 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.415 seconds
[0m02:36:29.995172 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:36:30.002803 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:36:30.004393 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 5.9245763, "process_in_blocks": "0", "process_kernel_time": 0.423194, "process_mem_max_rss": "201868", "process_out_blocks": "2168", "process_user_time": 4.135359}
[0m02:36:30.005030 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:36:30.004914 after 5.93 seconds
[0m02:36:30.005530 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:36:30.005991 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:36:30.039151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a1309ef30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a07947260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x776a07644560>]}
[0m02:36:30.039896 [debug] [MainThread]: Flushing usage events
[0m02:36:31.062303 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:38:47.302518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b463373e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b44fb39b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b44163e60>]}


============================== 02:38:47.310154 | f240186f-6209-49ef-82be-042bbae65dc1 ==============================
[0m02:38:47.310154 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:38:47.311185 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_path': 'Ai_Cortex/logs', 'indirect_selection': 'eager', 'warn_error': 'None', 'profiles_dir': 'Ai_Cortex', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_format': 'default', 'cache_selected_only': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'debug': 'False', 'static_parser': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'target_path': 'None', 'quiet': 'False', 'introspect': 'True', 'use_colors': 'True', 'empty': 'None', 'fail_fast': 'False'}
[0m02:38:47.866846 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:38:47.867504 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:38:47.868078 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:38:48.071354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f240186f-6209-49ef-82be-042bbae65dc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b3928fbc0>]}
[0m02:38:48.141708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f240186f-6209-49ef-82be-042bbae65dc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b39e85130>]}
[0m02:38:48.142645 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:38:48.319960 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:38:48.425644 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:38:48.426437 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:38:48.514168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f240186f-6209-49ef-82be-042bbae65dc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b3919da90>]}
[0m02:38:48.602647 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:38:48.604663 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:38:48.614918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f240186f-6209-49ef-82be-042bbae65dc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b38d3b170>]}
[0m02:38:48.615561 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:38:48.616158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f240186f-6209-49ef-82be-042bbae65dc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b38d0fbc0>]}
[0m02:38:48.616883 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:38:48.673675 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:38:48.674792 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:38:48.675829 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:38:53.512922 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.837 seconds
[0m02:38:53.514691 [info ] [MainThread]: "Removed extra comma in UNION ALL clause"
[0m02:38:53.522550 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:38:53.524038 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.2970214, "process_in_blocks": "0", "process_kernel_time": 0.463094, "process_mem_max_rss": "202188", "process_out_blocks": "2184", "process_user_time": 4.026125}
[0m02:38:53.524709 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:38:53.524590 after 6.30 seconds
[0m02:38:53.525193 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:38:53.525655 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:38:53.562408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b45e539b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b38d3b680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x775b38d0f3b0>]}
[0m02:38:53.563047 [debug] [MainThread]: Flushing usage events
[0m02:38:54.599384 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:42:12.374963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e2144639b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e213f02d80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e213f00ce0>]}


============================== 02:42:12.378323 | faa223e4-0064-464e-9358-9c8420643f84 ==============================
[0m02:42:12.378323 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:42:12.379112 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'version_check': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'log_cache_events': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'profiles_dir': 'Ai_Cortex', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'cache_selected_only': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'partial_parse': 'True', 'log_path': 'Ai_Cortex/logs', 'write_json': 'True', 'introspect': 'True', 'no_print': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'log_format': 'default'}
[0m02:42:12.924332 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:42:12.924999 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:42:12.925591 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:42:13.126709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faa223e4-0064-464e-9358-9c8420643f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e2144ce480>]}
[0m02:42:13.196785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'faa223e4-0064-464e-9358-9c8420643f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e2087db2c0>]}
[0m02:42:13.197777 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:42:13.410451 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:42:13.581946 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:42:13.583152 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:42:13.671543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'faa223e4-0064-464e-9358-9c8420643f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e208540860>]}
[0m02:42:13.751954 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:42:13.753781 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:42:13.763684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'faa223e4-0064-464e-9358-9c8420643f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e208373950>]}
[0m02:42:13.764274 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:42:13.764843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faa223e4-0064-464e-9358-9c8420643f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e208383620>]}
[0m02:42:13.765570 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:42:13.829355 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:42:13.830414 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:42:13.831325 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:42:18.570807 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.739 seconds
[0m02:42:18.572630 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:42:18.573229 [info ] [MainThread]: no
[0m02:42:18.581396 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:42:18.582488 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.268346, "process_in_blocks": "0", "process_kernel_time": 0.425385, "process_mem_max_rss": "202172", "process_out_blocks": "2176", "process_user_time": 4.168746}
[0m02:42:18.583198 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:42:18.583054 after 6.27 seconds
[0m02:42:18.583685 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:42:18.584176 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:42:18.917722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e213844890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e2083739b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71e208098c20>]}
[0m02:42:18.918435 [debug] [MainThread]: Flushing usage events
[0m02:42:20.035288 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:42:48.840419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768ddc8f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768de336b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768ddc8cfb0>]}


============================== 02:42:48.843980 | 85b7f036-4ed2-4f71-9454-2b5d57091d2c ==============================
[0m02:42:48.843980 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:42:48.844797 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'no_print': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'cache_selected_only': 'False', 'static_parser': 'True', 'printer_width': '80', 'target_path': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'log_path': 'Ai_Cortex/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'quiet': 'False', 'log_format': 'default', 'empty': 'None', 'write_json': 'True', 'profiles_dir': 'Ai_Cortex', 'log_cache_events': 'False', 'introspect': 'True'}
[0m02:42:49.377375 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:42:49.377996 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:42:49.378546 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:42:49.576922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '85b7f036-4ed2-4f71-9454-2b5d57091d2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d26a8200>]}
[0m02:42:49.647341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '85b7f036-4ed2-4f71-9454-2b5d57091d2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d4147170>]}
[0m02:42:49.648370 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:42:49.823787 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:42:49.935287 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:42:49.936089 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:42:50.023338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '85b7f036-4ed2-4f71-9454-2b5d57091d2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d2834d10>]}
[0m02:42:50.099471 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:42:50.102040 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:42:50.112168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '85b7f036-4ed2-4f71-9454-2b5d57091d2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d21e8d10>]}
[0m02:42:50.112748 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:42:50.113348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '85b7f036-4ed2-4f71-9454-2b5d57091d2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d25a6390>]}
[0m02:42:50.114051 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:42:50.204018 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:42:50.205341 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:42:50.206388 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:42:54.994192 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.788 seconds
[0m02:42:54.995961 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:42:54.996593 [info ] [MainThread]: 1
[0m02:42:54.997094 [info ] [MainThread]: no
[0m02:42:55.005583 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:42:55.006646 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.2277193, "process_in_blocks": "0", "process_kernel_time": 0.441515, "process_mem_max_rss": "202064", "process_out_blocks": "2176", "process_user_time": 4.081568}
[0m02:42:55.007278 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:42:55.007158 after 6.23 seconds
[0m02:42:55.007728 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:42:55.008185 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:42:55.047223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768ddd6d580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d1e66840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7768d1e70e00>]}
[0m02:42:55.047771 [debug] [MainThread]: Flushing usage events
[0m02:42:56.112342 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:43:26.308611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed536ef00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed50c3e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed4c0c860>]}


============================== 02:43:26.312048 | 8e2d2842-dced-4cc5-8766-3443b68d65d2 ==============================
[0m02:43:26.312048 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:43:26.312884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'version_check': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'target_path': 'None', 'empty': 'None', 'introspect': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'warn_error': 'None', 'log_path': 'Ai_Cortex/logs', 'profiles_dir': 'Ai_Cortex', 'indirect_selection': 'eager', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'no_print': 'None', 'debug': 'False'}
[0m02:43:26.840939 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:43:26.841581 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:43:26.842088 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:43:27.040293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e2d2842-dced-4cc5-8766-3443b68d65d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec9193620>]}
[0m02:43:27.110429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e2d2842-dced-4cc5-8766-3443b68d65d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed5098740>]}
[0m02:43:27.111495 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:43:27.310449 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:43:27.417254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:43:27.418090 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:43:27.424323 [error] [MainThread]: Encountered an error:
Compilation Error
  expected token 'end of statement block', got '='
    line 103
      {% if able=1 %}
[0m02:43:27.425550 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.1770648, "process_in_blocks": "16", "process_kernel_time": 0.422365, "process_mem_max_rss": "190912", "process_out_blocks": "16", "process_user_time": 3.866878}
[0m02:43:27.426358 [debug] [MainThread]: Command `dbt run-operation` failed at 02:43:27.426240 after 1.18 seconds
[0m02:43:27.426874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed4992510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec94bec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec8ef8a10>]}
[0m02:43:27.427406 [debug] [MainThread]: Flushing usage events
[0m02:43:28.562775 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:43:47.514303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753462812030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7534633e5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753462866f60>]}


============================== 02:43:47.517830 | 5547f95a-5b50-4bb3-9d60-e8e13bb04da6 ==============================
[0m02:43:47.517830 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:43:47.518667 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'write_json': 'True', 'target_path': 'None', 'empty': 'None', 'profiles_dir': 'Ai_Cortex', 'log_format': 'default', 'use_experimental_parser': 'False', 'debug': 'False', 'version_check': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'introspect': 'True', 'use_colors': 'True', 'no_print': 'None', 'partial_parse': 'True', 'printer_width': '80', 'log_path': 'Ai_Cortex/logs', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'quiet': 'False'}
[0m02:43:48.074771 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:43:48.075423 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:43:48.075991 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:43:48.275798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5547f95a-5b50-4bb3-9d60-e8e13bb04da6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753462ed8050>]}
[0m02:43:48.346547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5547f95a-5b50-4bb3-9d60-e8e13bb04da6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7534635502c0>]}
[0m02:43:48.347963 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:43:48.549296 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:43:48.660381 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:43:48.660921 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:43:48.701944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5547f95a-5b50-4bb3-9d60-e8e13bb04da6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753458084a40>]}
[0m02:43:48.781976 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:43:48.784096 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:43:48.794143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5547f95a-5b50-4bb3-9d60-e8e13bb04da6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75345756a9c0>]}
[0m02:43:48.794729 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:43:48.795333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5547f95a-5b50-4bb3-9d60-e8e13bb04da6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7534573d1ee0>]}
[0m02:43:48.796314 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:43:48.853361 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:43:48.854079 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:43:48.854694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:43:54.484092 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.629 seconds
[0m02:43:54.486781 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:43:54.487418 [info ] [MainThread]: 1
[0m02:43:54.487933 [info ] [MainThread]: no
[0m02:43:54.496204 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:43:54.497291 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 7.0455036, "process_in_blocks": "0", "process_kernel_time": 0.438335, "process_mem_max_rss": "201852", "process_out_blocks": "1112", "process_user_time": 4.215374}
[0m02:43:54.497897 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:43:54.497784 after 7.05 seconds
[0m02:43:54.498387 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:43:54.498840 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:43:54.534377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753463438e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753462ed9f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x753462edad20>]}
[0m02:43:54.534939 [debug] [MainThread]: Flushing usage events
[0m02:43:55.410497 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:44:54.193260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79635cee18e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79635c8d3860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79635c8d24b0>]}


============================== 02:44:54.196894 | 141974b4-15a0-45fc-98bf-3f5781af2354 ==============================
[0m02:44:54.196894 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:44:54.197789 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'debug': 'False', 'version_check': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'introspect': 'True', 'write_json': 'True', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'fail_fast': 'False', 'log_path': 'Ai_Cortex/logs', 'partial_parse': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'no_print': 'None', 'printer_width': '80', 'target_path': 'None', 'log_format': 'default', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'Ai_Cortex'}
[0m02:44:54.789925 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:44:54.790612 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:44:54.791196 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:44:55.000155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '141974b4-15a0-45fc-98bf-3f5781af2354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796352d002c0>]}
[0m02:44:55.071848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '141974b4-15a0-45fc-98bf-3f5781af2354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7963515d49b0>]}
[0m02:44:55.072976 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:44:55.250327 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:44:55.358852 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:44:55.359742 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:44:55.448423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '141974b4-15a0-45fc-98bf-3f5781af2354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796352144fe0>]}
[0m02:44:55.529335 [debug] [MainThread]: Wrote artifact WritableManifest to Ai_Cortex/target/manifest.json
[0m02:44:55.531241 [debug] [MainThread]: Wrote artifact SemanticManifest to Ai_Cortex/target/semantic_manifest.json
[0m02:44:55.541308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '141974b4-15a0-45fc-98bf-3f5781af2354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796350bae3f0>]}
[0m02:44:55.541890 [info ] [MainThread]: Found 2 models, 4 data tests, 508 macros
[0m02:44:55.542517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '141974b4-15a0-45fc-98bf-3f5781af2354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79635092a510>]}
[0m02:44:55.543247 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:44:55.600239 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:44:55.600973 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:44:55.601582 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:45:00.893035 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.291 seconds
[0m02:45:00.894814 [info ] [MainThread]: "Removed extra comma between UNION ALL statements"
[0m02:45:00.895446 [info ] [MainThread]: 1
[0m02:45:00.895981 [info ] [MainThread]: yes
[0m02:45:00.904348 [debug] [MainThread]: Wrote artifact RunResultsArtifact to Ai_Cortex/target/run_results.json
[0m02:45:00.905437 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.7744007, "process_in_blocks": "0", "process_kernel_time": 0.44468, "process_mem_max_rss": "201784", "process_out_blocks": "2176", "process_user_time": 4.203528}
[0m02:45:00.906070 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:45:00.905954 after 6.78 seconds
[0m02:45:00.906560 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:45:00.907043 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:45:00.968223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79635bdcab70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796351105100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796350ae9430>]}
[0m02:45:00.969372 [debug] [MainThread]: Flushing usage events
[0m02:45:02.065980 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:49:33.295935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x730230821400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73022eb754f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73022e787e00>]}


============================== 02:49:33.299466 | 5459a993-d1eb-4c04-a8c5-cb66acf87808 ==============================
[0m02:49:33.299466 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:49:33.300277 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'no_print': 'None', 'warn_error': 'None', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'empty': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'log_format': 'default', 'use_colors': 'True', 'printer_width': '80', 'debug': 'False', 'fail_fast': 'False', 'quiet': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml', 'target_path': 'None'}
[0m02:49:33.310418 [info ] [MainThread]: dbt version: 1.10.15
[0m02:49:33.310960 [info ] [MainThread]: python version: 3.12.1
[0m02:49:33.311517 [info ] [MainThread]: python path: /usr/local/python/3.12.1/bin/python3
[0m02:49:33.312034 [info ] [MainThread]: os info: Linux-6.8.0-1030-azure-x86_64-with-glibc2.39
[0m02:49:33.312590 [info ] [MainThread]: Using profiles dir at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml
[0m02:49:33.313089 [info ] [MainThread]: Using profiles.yml file at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/profiles.yml
[0m02:49:33.313607 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/dbt_project.yml
[0m02:49:33.440562 [info ] [MainThread]: Configuration:
[0m02:49:33.441220 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m02:49:33.441755 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:49:33.442290 [info ] [MainThread]: Required dependencies:
[0m02:49:33.442826 [debug] [MainThread]: Executing "git --help"
[0m02:49:33.445177 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:49:33.445696 [debug] [MainThread]: STDERR: "b''"
[0m02:49:33.446266 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:49:33.446830 [info ] [MainThread]: Connection test skipped since no profile was found
[0m02:49:33.447498 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:49:33.448269 [info ] [MainThread]: dbt looked for a profiles.yml file in /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m02:49:33.449858 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.21463543, "process_in_blocks": "0", "process_kernel_time": 0.220429, "process_mem_max_rss": "119232", "process_out_blocks": "16", "process_user_time": 2.754874}
[0m02:49:33.450672 [debug] [MainThread]: Command `dbt debug` failed at 02:49:33.450558 after 0.22 seconds
[0m02:49:33.451197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73022df07980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73022e787e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73022dc54d70>]}
[0m02:49:33.451729 [debug] [MainThread]: Flushing usage events
[0m02:49:34.590515 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:50:09.481650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ac7de3afa70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ac7de8dc5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ac7dfe4dbe0>]}


============================== 02:50:09.485175 | 3e4406cc-2bf6-4151-8c5d-e9fed3cb390a ==============================
[0m02:50:09.485175 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:50:09.485952 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'write_json': 'True', 'version_check': 'True', 'partial_parse': 'True', 'warn_error': 'None', 'introspect': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'empty': 'None', 'debug': 'False', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'log_cache_events': 'False', 'fail_fast': 'False', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml', 'use_colors': 'True', 'quiet': 'False', 'target_path': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'use_experimental_parser': 'False'}
[0m02:50:09.495867 [info ] [MainThread]: dbt version: 1.10.15
[0m02:50:09.496470 [info ] [MainThread]: python version: 3.12.1
[0m02:50:09.497000 [info ] [MainThread]: python path: /usr/local/python/3.12.1/bin/python3
[0m02:50:09.497532 [info ] [MainThread]: os info: Linux-6.8.0-1030-azure-x86_64-with-glibc2.39
[0m02:50:09.498057 [info ] [MainThread]: Using profiles dir at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml
[0m02:50:09.498581 [info ] [MainThread]: Using profiles.yml file at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/profiles.yml
[0m02:50:09.499085 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/dbt_project.yml
[0m02:50:09.666944 [info ] [MainThread]: Configuration:
[0m02:50:09.670217 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m02:50:09.671397 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:50:09.672342 [info ] [MainThread]: Required dependencies:
[0m02:50:09.673194 [debug] [MainThread]: Executing "git --help"
[0m02:50:09.676716 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:50:09.677751 [debug] [MainThread]: STDERR: "b''"
[0m02:50:09.678745 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:50:09.679871 [info ] [MainThread]: Connection test skipped since no profile was found
[0m02:50:09.680776 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:50:09.682298 [info ] [MainThread]: dbt looked for a profiles.yml file in /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m02:50:09.684357 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.26426622, "process_in_blocks": "0", "process_kernel_time": 0.213872, "process_mem_max_rss": "119760", "process_out_blocks": "24", "process_user_time": 2.912644}
[0m02:50:09.685931 [debug] [MainThread]: Command `dbt debug` failed at 02:50:09.685376 after 0.27 seconds
[0m02:50:09.687548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ac7dda9c560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ac7de8ffa40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ac7de8ffd40>]}
[0m02:50:09.688498 [debug] [MainThread]: Flushing usage events
[0m02:50:10.754588 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:50:34.007193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7832977a1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7832970a36e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7832970a3e30>]}


============================== 02:50:34.010614 | c8ed0971-a343-4cfa-b14f-650173b7e25c ==============================
[0m02:50:34.010614 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:50:34.011429 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'printer_width': '80', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'fail_fast': 'False', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'version_check': 'True', 'introspect': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'debug': 'False', 'partial_parse': 'True', 'empty': 'None', 'indirect_selection': 'eager', 'target_path': 'None', 'quiet': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'no_print': 'None'}
[0m02:50:34.021476 [info ] [MainThread]: dbt version: 1.10.15
[0m02:50:34.022023 [info ] [MainThread]: python version: 3.12.1
[0m02:50:34.022572 [info ] [MainThread]: python path: /usr/local/python/3.12.1/bin/python3
[0m02:50:34.023084 [info ] [MainThread]: os info: Linux-6.8.0-1030-azure-x86_64-with-glibc2.39
[0m02:50:34.564730 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:50:34.565633 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:50:34.566364 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:50:34.633206 [info ] [MainThread]: Using profiles dir at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/
[0m02:50:34.633910 [info ] [MainThread]: Using profiles.yml file at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/profiles.yml
[0m02:50:34.634475 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/AI_Cortex_Snowflake/Ai_Cortex/dbt_project.yml
[0m02:50:34.635223 [info ] [MainThread]: adapter type: snowflake
[0m02:50:34.635726 [info ] [MainThread]: adapter version: 1.10.3
[0m02:50:34.759997 [info ] [MainThread]: Configuration:
[0m02:50:34.760738 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:50:34.761338 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:50:34.761935 [info ] [MainThread]: Required dependencies:
[0m02:50:34.762534 [debug] [MainThread]: Executing "git --help"
[0m02:50:34.765047 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:50:34.765689 [debug] [MainThread]: STDERR: "b''"
[0m02:50:34.766160 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:50:34.766735 [info ] [MainThread]: Connection:
[0m02:50:34.767450 [info ] [MainThread]:   account: GXUGAIL-QU64760
[0m02:50:34.768161 [info ] [MainThread]:   user: saravanapandi
[0m02:50:34.768869 [info ] [MainThread]:   database: ai_cortex
[0m02:50:34.769505 [info ] [MainThread]:   warehouse: compute_wh
[0m02:50:34.770166 [info ] [MainThread]:   role: accountadmin
[0m02:50:34.770801 [info ] [MainThread]:   schema: public
[0m02:50:34.771519 [info ] [MainThread]:   authenticator: None
[0m02:50:34.772302 [info ] [MainThread]:   oauth_client_id: None
[0m02:50:34.773012 [info ] [MainThread]:   query_tag: None
[0m02:50:34.773693 [info ] [MainThread]:   client_session_keep_alive: False
[0m02:50:34.774420 [info ] [MainThread]:   host: None
[0m02:50:34.775140 [info ] [MainThread]:   port: None
[0m02:50:34.775853 [info ] [MainThread]:   proxy_host: None
[0m02:50:34.776583 [info ] [MainThread]:   proxy_port: None
[0m02:50:34.777351 [info ] [MainThread]:   protocol: None
[0m02:50:34.778132 [info ] [MainThread]:   connect_retries: 1
[0m02:50:34.778845 [info ] [MainThread]:   connect_timeout: None
[0m02:50:34.779544 [info ] [MainThread]:   retry_on_database_errors: False
[0m02:50:34.780280 [info ] [MainThread]:   retry_all: False
[0m02:50:34.780996 [info ] [MainThread]:   insecure_mode: False
[0m02:50:34.781772 [info ] [MainThread]:   reuse_connections: True
[0m02:50:34.782483 [info ] [MainThread]:   s3_stage_vpce_dns_name: None
[0m02:50:34.783090 [info ] [MainThread]:   platform_detection_timeout_seconds: 0.0
[0m02:50:34.783856 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:50:34.988911 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m02:50:35.017367 [debug] [MainThread]: Using snowflake connection "debug"
[0m02:50:35.017879 [debug] [MainThread]: On debug: select 1 as id
[0m02:50:35.018360 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:50:36.209226 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.191 seconds
[0m02:50:36.210525 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:50:36.211152 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:50:36.212647 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.265658, "process_in_blocks": "0", "process_kernel_time": 0.408502, "process_mem_max_rss": "197636", "process_out_blocks": "48", "process_user_time": 3.647626}
[0m02:50:36.213711 [debug] [MainThread]: Command `dbt debug` succeeded at 02:50:36.213592 after 2.27 seconds
[0m02:50:36.214197 [debug] [MainThread]: Connection 'debug' was left open.
[0m02:50:36.214656 [debug] [MainThread]: On debug: Close
[0m02:50:36.261644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78329864b740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x783298b0f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78328b39b080>]}
[0m02:50:36.262280 [debug] [MainThread]: Flushing usage events
[0m02:50:37.381484 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:50:49.334526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784ebd46a1b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784ebd4a5ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784ebe4b2a50>]}


============================== 02:50:49.337976 | 421639bb-322a-466d-9b99-69d0ca2cdf5c ==============================
[0m02:50:49.337976 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:50:49.338807 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'log_format': 'default', 'debug': 'False', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'fail_fast': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'printer_width': '80', 'introspect': 'True', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'target_path': 'None', 'empty': 'None', 'write_json': 'True'}
[0m02:50:49.876206 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:50:49.876838 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:50:49.877404 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:50:50.080462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '421639bb-322a-466d-9b99-69d0ca2cdf5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784ebee58f20>]}
[0m02:50:50.178058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '421639bb-322a-466d-9b99-69d0ca2cdf5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784eb2667290>]}
[0m02:50:50.179070 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:50:50.364766 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:50:50.485691 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m02:50:50.486442 [debug] [MainThread]: Partial parsing: added file: Ai_Cortex://models/example/sample.sql
[0m02:50:50.781600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '421639bb-322a-466d-9b99-69d0ca2cdf5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784eb1dc2150>]}
[0m02:50:50.873309 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m02:50:50.875165 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m02:50:50.885272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '421639bb-322a-466d-9b99-69d0ca2cdf5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784eb223fef0>]}
[0m02:50:50.885858 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m02:50:50.886455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '421639bb-322a-466d-9b99-69d0ca2cdf5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784eb2090f20>]}
[0m02:50:50.887165 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:50:51.061865 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:50:51.062663 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:50:51.063535 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:50:56.677250 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.614 seconds
[0m02:50:56.679043 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:50:56.679626 [info ] [MainThread]: 1
[0m02:50:56.680151 [info ] [MainThread]: yes
[0m02:50:56.687354 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m02:50:56.688441 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 7.4143243, "process_in_blocks": "0", "process_kernel_time": 0.416066, "process_mem_max_rss": "202628", "process_out_blocks": "2184", "process_user_time": 4.377174}
[0m02:50:56.689047 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:50:56.688935 after 7.42 seconds
[0m02:50:56.689539 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:50:56.689989 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:50:56.738904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784ebe39af30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784eb1659370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x784eb1e47dd0>]}
[0m02:50:56.739609 [debug] [MainThread]: Flushing usage events
[0m02:50:57.680643 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:51:55.732434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373adee2a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373ae9772c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373ad547560>]}


============================== 02:51:55.737487 | 40a34ae1-f87b-45fd-8323-5ae7bb592140 ==============================
[0m02:51:55.737487 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:51:55.738539 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'debug': 'False', 'version_check': 'True', 'write_json': 'True', 'fail_fast': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'target_path': 'None', 'no_print': 'None', 'warn_error': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'printer_width': '80', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'static_parser': 'True', 'quiet': 'False', 'empty': 'None', 'introspect': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:51:56.330373 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:51:56.331008 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:51:56.331632 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:51:56.530851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '40a34ae1-f87b-45fd-8323-5ae7bb592140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373a45bfef0>]}
[0m02:51:56.600915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '40a34ae1-f87b-45fd-8323-5ae7bb592140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373acb9f4d0>]}
[0m02:51:56.601911 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:51:56.772671 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:51:56.879236 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:51:56.879982 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/example/sample.sql
[0m02:51:56.880649 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:51:57.200833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40a34ae1-f87b-45fd-8323-5ae7bb592140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373a1931220>]}
[0m02:51:57.279953 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m02:51:57.281875 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m02:51:57.291866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40a34ae1-f87b-45fd-8323-5ae7bb592140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373a18dac90>]}
[0m02:51:57.292484 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m02:51:57.292996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40a34ae1-f87b-45fd-8323-5ae7bb592140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373a1324e90>]}
[0m02:51:57.293714 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:51:57.346880 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:51:57.347574 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:51:57.348178 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:52:02.208665 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.860 seconds
[0m02:52:02.210537 [info ] [MainThread]: "Removed extra comma between UNION ALL statements"
[0m02:52:02.211094 [info ] [MainThread]: 1
[0m02:52:02.211597 [info ] [MainThread]: yes
[0m02:52:02.218764 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m02:52:02.219829 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.548972, "process_in_blocks": "0", "process_kernel_time": 0.41372, "process_mem_max_rss": "205356", "process_out_blocks": "2184", "process_user_time": 4.446774}
[0m02:52:02.220487 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:52:02.220368 after 6.55 seconds
[0m02:52:02.220946 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:52:02.221416 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:52:02.261366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373a18daea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373adbeb9e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7373a13364b0>]}
[0m02:52:02.262168 [debug] [MainThread]: Flushing usage events
[0m02:52:03.285100 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:52:06.760403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e044529d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e04441aaab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e0444248c20>]}


============================== 02:52:06.763992 | 980693ea-1c06-462f-b953-ac672ffd755e ==============================
[0m02:52:06.763992 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:52:06.764725 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'fail_fast': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'log_cache_events': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'use_colors': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'write_json': 'True', 'quiet': 'False', 'warn_error': 'None', 'introspect': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'cache_selected_only': 'False', 'printer_width': '80', 'empty': 'None', 'no_print': 'None'}
[0m02:52:07.301806 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:52:07.302472 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:52:07.302989 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:52:07.509109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '980693ea-1c06-462f-b953-ac672ffd755e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e0444e3d1f0>]}
[0m02:52:07.587286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '980693ea-1c06-462f-b953-ac672ffd755e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e04391a36b0>]}
[0m02:52:07.588711 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:52:07.843154 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:52:07.952022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:52:07.952573 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:52:07.993275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '980693ea-1c06-462f-b953-ac672ffd755e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e04391c6a50>]}
[0m02:52:08.096043 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m02:52:08.099480 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m02:52:08.111686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '980693ea-1c06-462f-b953-ac672ffd755e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e0438d07ef0>]}
[0m02:52:08.112660 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m02:52:08.113292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '980693ea-1c06-462f-b953-ac672ffd755e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e0438d0cad0>]}
[0m02:52:08.114021 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:52:08.169987 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:52:08.170725 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:52:08.171336 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:52:13.618631 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.447 seconds
[0m02:52:13.620433 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:52:13.620944 [info ] [MainThread]: 1
[0m02:52:13.621438 [info ] [MainThread]: yes
[0m02:52:13.628805 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m02:52:13.629908 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.9329786, "process_in_blocks": "0", "process_kernel_time": 0.454418, "process_mem_max_rss": "201984", "process_out_blocks": "1112", "process_user_time": 4.078831}
[0m02:52:13.630558 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:52:13.630442 after 6.93 seconds
[0m02:52:13.631012 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:52:13.631500 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:52:13.671951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e04448bd4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e0438d06c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e0438a583e0>]}
[0m02:52:13.672564 [debug] [MainThread]: Flushing usage events
[0m02:52:14.665197 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:56:40.579785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1d476e4b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1d4ef82c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1d476e540>]}


============================== 02:56:40.583286 | b8b43ae0-592d-4e2f-a4ff-6ebdb6eac669 ==============================
[0m02:56:40.583286 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:56:40.584016 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'quiet': 'False', 'partial_parse': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'use_colors': 'True', 'fail_fast': 'False', 'printer_width': '80', 'log_format': 'default', 'target_path': 'None', 'indirect_selection': 'eager', 'warn_error': 'None', 'write_json': 'True', 'static_parser': 'True', 'empty': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'log_cache_events': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True'}
[0m02:56:41.122092 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:56:41.122731 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:56:41.123264 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:56:41.325981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8b43ae0-592d-4e2f-a4ff-6ebdb6eac669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c94f2900>]}
[0m02:56:41.400611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b8b43ae0-592d-4e2f-a4ff-6ebdb6eac669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c92331a0>]}
[0m02:56:41.401605 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:56:41.573321 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:56:41.699018 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:56:41.699737 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:56:41.742487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b8b43ae0-592d-4e2f-a4ff-6ebdb6eac669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c91e0bf0>]}
[0m02:56:41.816875 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m02:56:41.818719 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m02:56:41.828677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b8b43ae0-592d-4e2f-a4ff-6ebdb6eac669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c8d2eb40>]}
[0m02:56:41.829268 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m02:56:41.829781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8b43ae0-592d-4e2f-a4ff-6ebdb6eac669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c8d34740>]}
[0m02:56:41.830510 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:56:41.883280 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:56:41.883937 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:56:41.884543 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:56:46.389895 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.505 seconds
[0m02:56:46.391663 [info ] [MainThread]: "Removed extra comma between UNION ALL statements"
[0m02:56:46.392186 [info ] [MainThread]: 1
[0m02:56:46.392652 [info ] [MainThread]: yes
[0m02:56:46.399919 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m02:56:46.400965 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 5.895217, "process_in_blocks": "0", "process_kernel_time": 0.413234, "process_mem_max_rss": "201952", "process_out_blocks": "1128", "process_user_time": 4.045718}
[0m02:56:46.401612 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:56:46.401497 after 5.90 seconds
[0m02:56:46.402062 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:56:46.402536 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:56:46.452405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1d5002a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c8d2f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78e1c8a78d40>]}
[0m02:56:46.453022 [debug] [MainThread]: Flushing usage events
[0m02:56:47.585354 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:58:36.676462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e2a80ff110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e2a8855640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e2a80fe000>]}


============================== 02:58:36.679965 | 152cd532-f3c3-4390-9bcf-e1b3f44e0244 ==============================
[0m02:58:36.679965 [info ] [MainThread]: Running with dbt=1.10.15
[0m02:58:36.680733 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'partial_parse': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'target_path': 'None', 'debug': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'log_cache_events': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'use_colors': 'True', 'no_print': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'quiet': 'False', 'empty': 'None', 'warn_error': 'None'}
[0m02:58:37.202938 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m02:58:37.203611 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m02:58:37.204147 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m02:58:37.420376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '152cd532-f3c3-4390-9bcf-e1b3f44e0244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e29cb18fe0>]}
[0m02:58:37.503907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '152cd532-f3c3-4390-9bcf-e1b3f44e0244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e29e5da690>]}
[0m02:58:37.504859 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m02:58:37.677786 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m02:58:37.784147 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:58:37.784948 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m02:58:37.871725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '152cd532-f3c3-4390-9bcf-e1b3f44e0244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e2a7996210>]}
[0m02:58:37.948751 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m02:58:37.951425 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m02:58:37.961583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '152cd532-f3c3-4390-9bcf-e1b3f44e0244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e29c5a3f50>]}
[0m02:58:37.962195 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m02:58:37.962710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '152cd532-f3c3-4390-9bcf-e1b3f44e0244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e2a77bf590>]}
[0m02:58:37.963418 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m02:58:38.016222 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m02:58:38.016941 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m02:58:38.017560 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:58:43.733567 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.716 seconds
[0m02:58:43.735389 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m02:58:43.735903 [info ] [MainThread]: 1
[0m02:58:43.736427 [info ] [MainThread]: "/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing \"table\" to \"view\" below\n*/\n\n{{ config(materialized='table') }}\n\nWITH source_data AS (\n\n    SELECT 1 AS id\n    UNION ALL\n    SELECT null AS id\n\n)\n\nSELECT *\nFROM source_data;\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null\n"
[0m02:58:43.743667 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m02:58:43.744741 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 7.129403, "process_in_blocks": "0", "process_kernel_time": 0.435339, "process_mem_max_rss": "202072", "process_out_blocks": "2176", "process_user_time": 4.052539}
[0m02:58:43.745366 [debug] [MainThread]: Command `dbt run-operation` succeeded at 02:58:43.745251 after 7.13 seconds
[0m02:58:43.745825 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m02:58:43.746305 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m02:58:43.786551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e29c5a37d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e29c2b2c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76e29c5ed010>]}
[0m02:58:43.787097 [debug] [MainThread]: Flushing usage events
[0m02:58:44.911090 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:01:03.141564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e6f2e2ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e6fd39e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e6ee33170>]}


============================== 03:01:03.144908 | e2ddb161-8ac0-4ccb-8402-4647f10cacc2 ==============================
[0m03:01:03.144908 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:01:03.145664 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'log_cache_events': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'log_format': 'default', 'write_json': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'printer_width': '80', 'cache_selected_only': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'quiet': 'False', 'partial_parse': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'empty': 'None', 'introspect': 'True', 'no_print': 'None'}
[0m03:01:03.702502 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:01:03.703393 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:01:03.704035 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:01:03.908390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e2ddb161-8ac0-4ccb-8402-4647f10cacc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e71162780>]}
[0m03:01:03.981221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e2ddb161-8ac0-4ccb-8402-4647f10cacc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e66343950>]}
[0m03:01:03.982160 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:01:04.153486 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:01:04.259195 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:01:04.259993 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m03:01:04.371501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2ddb161-8ac0-4ccb-8402-4647f10cacc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e63786840>]}
[0m03:01:04.450233 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:01:04.452153 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:01:04.462099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e2ddb161-8ac0-4ccb-8402-4647f10cacc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e63786990>]}
[0m03:01:04.462720 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m03:01:04.463244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2ddb161-8ac0-4ccb-8402-4647f10cacc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e63752ff0>]}
[0m03:01:04.463931 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:01:04.516754 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:01:04.517433 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:01:04.518023 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:01:09.213432 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.695 seconds
[0m03:01:09.215236 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m03:01:09.215756 [info ] [MainThread]: 1
[0m03:01:09.216326 [info ] [MainThread]: "/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing \"table\" to \"view\" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
"
[0m03:01:09.223561 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:01:09.224624 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.1436944, "process_in_blocks": "0", "process_kernel_time": 0.43375, "process_mem_max_rss": "202028", "process_out_blocks": "2176", "process_user_time": 4.155002}
[0m03:01:09.225259 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:01:09.225141 after 6.14 seconds
[0m03:01:09.225724 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:01:09.226194 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:01:09.259572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e6ea77140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e63787770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c8e63c58b30>]}
[0m03:01:09.260151 [debug] [MainThread]: Flushing usage events
[0m03:01:10.280486 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:01:36.440166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d29329c500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d29377fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d2933f6780>]}


============================== 03:01:36.443583 | 5fde8245-bc8e-49ce-a578-e88a8ff254af ==============================
[0m03:01:36.443583 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:01:36.444387 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'debug': 'False', 'version_check': 'True', 'write_json': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'log_format': 'default', 'use_colors': 'True', 'target_path': 'None', 'static_parser': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}'}
[0m03:01:37.006874 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:01:37.007536 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:01:37.008098 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:01:37.207635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5fde8245-bc8e-49ce-a578-e88a8ff254af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d28a884860>]}
[0m03:01:37.277334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5fde8245-bc8e-49ce-a578-e88a8ff254af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d2879a4f20>]}
[0m03:01:37.278427 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:01:37.448934 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:01:37.553386 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:01:37.554135 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/example/sample.sql
[0m03:01:37.838863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fde8245-bc8e-49ce-a578-e88a8ff254af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d28756fe30>]}
[0m03:01:37.910567 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:01:37.912445 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:01:37.922443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fde8245-bc8e-49ce-a578-e88a8ff254af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d287876c60>]}
[0m03:01:37.923079 [info ] [MainThread]: Found 3 models, 4 data tests, 508 macros
[0m03:01:37.923673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fde8245-bc8e-49ce-a578-e88a8ff254af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d28756fd40>]}
[0m03:01:37.924377 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:01:38.095464 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:01:38.096227 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:01:38.096827 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:01:42.927165 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.830 seconds
[0m03:01:42.928913 [info ] [MainThread]: "Removed extra comma between UNION ALL statements"
[0m03:01:42.929504 [info ] [MainThread]: 1
[0m03:01:42.930064 [info ] [MainThread]: "/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing \"table\" to \"view\" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
"
[0m03:01:42.938444 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:01:42.939525 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.560015, "process_in_blocks": "0", "process_kernel_time": 0.448372, "process_mem_max_rss": "202516", "process_out_blocks": "2176", "process_user_time": 4.295409}
[0m03:01:42.940164 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:01:42.940017 after 6.56 seconds
[0m03:01:42.940632 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:01:42.941081 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:01:42.972418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d292a66b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d287876d20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d2875c2de0>]}
[0m03:01:42.972957 [debug] [MainThread]: Flushing usage events
[0m03:01:44.032059 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:02:00.803176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77434b008b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77434b262390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77434a6ef170>]}


============================== 03:02:00.806562 | 72001a42-d2f3-4be2-9acf-36572c8304b3 ==============================
[0m03:02:00.806562 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:02:00.807362 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'cache_selected_only': 'False', 'version_check': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'indirect_selection': 'eager', 'static_parser': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'debug': 'False', 'printer_width': '80', 'log_format': 'default', 'fail_fast': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'empty': 'None', 'write_json': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True'}
[0m03:02:01.353024 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:02:01.353679 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:02:01.354198 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:02:01.554436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '72001a42-d2f3-4be2-9acf-36572c8304b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77433f619130>]}
[0m03:02:01.624283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '72001a42-d2f3-4be2-9acf-36572c8304b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77433facb860>]}
[0m03:02:01.625271 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:02:01.797650 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:02:02.010653 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m03:02:02.011756 [debug] [MainThread]: Partial parsing: added file: Ai_Cortex://models/sample.sql
[0m03:02:02.325441 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "sample".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("sample").
  
  To fix this, change the name of one of these resources:
  - model.Ai_Cortex.sample (models/sample.sql)
  - model.Ai_Cortex.sample (models/example/sample.sql)
[0m03:02:02.326787 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.5847824, "process_in_blocks": "0", "process_kernel_time": 0.410551, "process_mem_max_rss": "193280", "process_out_blocks": "16", "process_user_time": 4.081661}
[0m03:02:02.327539 [debug] [MainThread]: Command `dbt run-operation` failed at 03:02:02.327421 after 1.59 seconds
[0m03:02:02.328060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77434a6ef170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77433f159340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77434ad601a0>]}
[0m03:02:02.328617 [debug] [MainThread]: Flushing usage events
[0m03:02:03.338064 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:02:33.834355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1db22b3e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1db591d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1dd2217f0>]}


============================== 03:02:33.837775 | b39d4e2a-f14b-4308-9fc0-23901ad2d33c ==============================
[0m03:02:33.837775 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:02:33.838606 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'use_colors': 'True', 'empty': 'None', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'printer_width': '80', 'cache_selected_only': 'False', 'debug': 'False', 'fail_fast': 'False', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'use_experimental_parser': 'False', 'version_check': 'True', 'warn_error': 'None', 'no_print': 'None', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}'}
[0m03:02:34.355056 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:02:34.355711 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:02:34.356234 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:02:34.563764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b39d4e2a-f14b-4308-9fc0-23901ad2d33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1cf8123f0>]}
[0m03:02:34.666870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b39d4e2a-f14b-4308-9fc0-23901ad2d33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1d204f6b0>]}
[0m03:02:34.667975 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:02:34.847664 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:02:34.988748 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m03:02:34.989506 [debug] [MainThread]: Partial parsing: added file: Ai_Cortex://models/sample_@.sql
[0m03:02:35.323858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b39d4e2a-f14b-4308-9fc0-23901ad2d33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1cf3daea0>]}
[0m03:02:35.396984 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:02:35.399033 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:02:35.409985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b39d4e2a-f14b-4308-9fc0-23901ad2d33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1cf3dae40>]}
[0m03:02:35.410700 [info ] [MainThread]: Found 4 models, 4 data tests, 508 macros
[0m03:02:35.411328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b39d4e2a-f14b-4308-9fc0-23901ad2d33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1cf3a29f0>]}
[0m03:02:35.412073 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:02:35.466754 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:02:35.467523 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:02:35.468145 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:02:40.491516 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.023 seconds
[0m03:02:40.493308 [info ] [MainThread]: "Removed extra comma in UNION ALL clause"
[0m03:02:40.493865 [info ] [MainThread]: 1
[0m03:02:40.494435 [info ] [MainThread]: "/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing \"table\" to \"view\" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null"
[0m03:02:40.501637 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:02:40.502730 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.7292027, "process_in_blocks": "0", "process_kernel_time": 0.443241, "process_mem_max_rss": "204936", "process_out_blocks": "2200", "process_user_time": 4.515609}
[0m03:02:40.503359 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:02:40.503246 after 6.73 seconds
[0m03:02:40.503817 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:02:40.504299 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:02:40.543372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1da986b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1cf3a2240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76b1db1a8470>]}
[0m03:02:40.543931 [debug] [MainThread]: Flushing usage events
[0m03:02:41.435818 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:04:55.314171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613cd8f5970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613ce610c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613cd2f2ff0>]}


============================== 03:04:55.317501 | 5b0c97e6-488f-4015-869c-20397c96ae81 ==============================
[0m03:04:55.317501 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:04:55.318283 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'empty': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'write_json': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'debug': 'False', 'target_path': 'None', 'log_format': 'default', 'fail_fast': 'False', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'log_cache_events': 'False', 'version_check': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'static_parser': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'printer_width': '80', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m03:04:55.889750 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:04:55.890405 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:04:55.890981 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:04:56.090379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b0c97e6-488f-4015-869c-20397c96ae81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c199ffb0>]}
[0m03:04:56.159617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b0c97e6-488f-4015-869c-20397c96ae81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c22408f0>]}
[0m03:04:56.160521 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:04:56.372423 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:04:56.479454 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m03:04:56.480275 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m03:04:56.480855 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/sample_@.sql
[0m03:04:56.823509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b0c97e6-488f-4015-869c-20397c96ae81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c1552780>]}
[0m03:04:56.895699 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:04:56.897556 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:04:56.907512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b0c97e6-488f-4015-869c-20397c96ae81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c1552900>]}
[0m03:04:56.908078 [info ] [MainThread]: Found 4 models, 4 data tests, 508 macros
[0m03:04:56.908683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b0c97e6-488f-4015-869c-20397c96ae81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c152ce90>]}
[0m03:04:56.909384 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:04:56.963976 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:04:56.964688 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:04:56.965284 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:05:02.808606 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.843 seconds
[0m03:05:02.810400 [info ] [MainThread]: "Removed extra comma between UNION ALL statements"
[0m03:05:02.810951 [info ] [MainThread]: 1
[0m03:05:02.811551 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:05:02.818715 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:05:02.819780 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 7.571549, "process_in_blocks": "0", "process_kernel_time": 0.478199, "process_mem_max_rss": "205108", "process_out_blocks": "2208", "process_user_time": 4.420358}
[0m03:05:02.820421 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:05:02.820309 after 7.57 seconds
[0m03:05:02.820877 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:05:02.821357 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:05:02.876357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613ccfe4590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c1552c60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7613c0d6cef0>]}
[0m03:05:02.876984 [debug] [MainThread]: Flushing usage events
[0m03:05:03.924447 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:05:23.841734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df33b5c8b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df33b078b60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df33b07b560>]}


============================== 03:05:23.845193 | 336f8870-bfe7-48df-b78b-525969e51fc8 ==============================
[0m03:05:23.845193 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:05:23.845943 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'log_cache_events': 'False', 'partial_parse': 'True', 'no_print': 'None', 'use_colors': 'True', 'quiet': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'debug': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'empty': 'None', 'log_format': 'default', 'write_json': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'fail_fast': 'False', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'use_experimental_parser': 'False'}
[0m03:05:24.423263 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:05:24.423910 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:05:24.424517 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:05:24.629347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '336f8870-bfe7-48df-b78b-525969e51fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32fc95eb0>]}
[0m03:05:24.699975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '336f8870-bfe7-48df-b78b-525969e51fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df33b5c8ef0>]}
[0m03:05:24.701013 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:05:24.877060 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:05:24.985377 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:05:24.986112 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/sample_@.sql
[0m03:05:25.302746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '336f8870-bfe7-48df-b78b-525969e51fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32f4a9100>]}
[0m03:05:25.443511 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:05:25.446626 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:05:25.461503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '336f8870-bfe7-48df-b78b-525969e51fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32f70e180>]}
[0m03:05:25.462431 [info ] [MainThread]: Found 4 models, 4 data tests, 508 macros
[0m03:05:25.463256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '336f8870-bfe7-48df-b78b-525969e51fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32fb8c920>]}
[0m03:05:25.466750 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:05:25.531195 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:05:25.531890 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:05:25.532547 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:05:30.211107 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.679 seconds
[0m03:05:30.212927 [info ] [MainThread]: "Removed extra comma after UNION ALL"
[0m03:05:30.213507 [info ] [MainThread]: 1
[0m03:05:30.214076 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:05:30.221319 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:05:30.222398 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.4583387, "process_in_blocks": "0", "process_kernel_time": 0.447134, "process_mem_max_rss": "205500", "process_out_blocks": "2208", "process_user_time": 4.441111}
[0m03:05:30.223012 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:05:30.222899 after 6.46 seconds
[0m03:05:30.223488 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:05:30.223934 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:05:30.257478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32f70c140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32f48bf80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7df32ecd8aa0>]}
[0m03:05:30.258029 [debug] [MainThread]: Flushing usage events
[0m03:05:31.061433 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:08:25.292603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcffc5b61b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcffc4d6240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcffc1cc620>]}


============================== 03:08:25.295986 | aaa69755-5f85-489c-ac65-9ef08194e9c5 ==============================
[0m03:08:25.295986 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:08:25.296832 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'version_check': 'True', 'write_json': 'True', 'printer_width': '80', 'empty': 'None', 'indirect_selection': 'eager', 'use_colors': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'target_path': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'use_experimental_parser': 'False', 'introspect': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'fail_fast': 'False', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'warn_error': 'None', 'debug': 'False'}
[0m03:08:25.865477 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:08:25.866165 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:08:25.866743 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:08:26.068073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aaa69755-5f85-489c-ac65-9ef08194e9c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcffb92b1a0>]}
[0m03:08:26.137472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aaa69755-5f85-489c-ac65-9ef08194e9c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcffccae450>]}
[0m03:08:26.138548 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:08:26.318870 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:08:26.434372 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:08:26.435187 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/sample_@.sql
[0m03:08:26.769049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aaa69755-5f85-489c-ac65-9ef08194e9c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcff0481ac0>]}
[0m03:08:26.862752 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:08:26.866033 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:08:26.881797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aaa69755-5f85-489c-ac65-9ef08194e9c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcff075a0c0>]}
[0m03:08:26.882777 [info ] [MainThread]: Found 4 models, 4 data tests, 508 macros
[0m03:08:26.883728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aaa69755-5f85-489c-ac65-9ef08194e9c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcff04d6570>]}
[0m03:08:26.884847 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:08:26.941186 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:08:26.941896 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:08:26.942518 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:08:32.070306 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.128 seconds
[0m03:08:32.072084 [info ] [MainThread]: "Removed extra comma between UNION ALL statements"
[0m03:08:32.072674 [info ] [MainThread]: 1
[0m03:08:32.073266 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:08:32.080547 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:08:32.081611 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.8492913, "process_in_blocks": "0", "process_kernel_time": 0.451331, "process_mem_max_rss": "205592", "process_out_blocks": "2192", "process_user_time": 4.441458}
[0m03:08:32.082253 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:08:32.082109 after 6.85 seconds
[0m03:08:32.082722 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:08:32.083188 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:08:32.122902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcff075a840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcff0590440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfefd4e7e0>]}
[0m03:08:32.123472 [debug] [MainThread]: Flushing usage events
[0m03:08:33.190944 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:09:05.107361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efeda1a510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efed74a630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efed749a00>]}


============================== 03:09:05.110757 | 000db9fd-5d0f-434f-b0c4-f43ac9879767 ==============================
[0m03:09:05.110757 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:09:05.111585 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'use_colors': 'True', 'log_format': 'default', 'no_print': 'None', 'cache_selected_only': 'False', 'quiet': 'False', 'fail_fast': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {model_name: my_first_dbt_model}', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'empty': 'None', 'printer_width': '80', 'warn_error': 'None', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'version_check': 'True', 'partial_parse': 'True'}
[0m03:09:05.666821 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:09:05.667513 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:09:05.668132 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:09:05.871792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '000db9fd-5d0f-434f-b0c4-f43ac9879767', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efecfb3f20>]}
[0m03:09:05.944029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '000db9fd-5d0f-434f-b0c4-f43ac9879767', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efe1e393a0>]}
[0m03:09:05.945005 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:09:06.148576 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:09:06.297142 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:09:06.297892 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/sample_@.sql
[0m03:09:06.588359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '000db9fd-5d0f-434f-b0c4-f43ac9879767', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efe141a2d0>]}
[0m03:09:06.661494 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:09:06.663465 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:09:06.673653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '000db9fd-5d0f-434f-b0c4-f43ac9879767', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efe158c410>]}
[0m03:09:06.674279 [info ] [MainThread]: Found 4 models, 4 data tests, 508 macros
[0m03:09:06.675064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '000db9fd-5d0f-434f-b0c4-f43ac9879767', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efe167b290>]}
[0m03:09:06.675803 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:09:06.746416 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:09:06.747187 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:09:06.747786 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:09:11.770609 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.023 seconds
[0m03:09:11.772440 [info ] [MainThread]: "Removed extra comma in UNION ALL clause"
[0m03:09:11.772999 [info ] [MainThread]: 1
[0m03:09:11.773634 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
[0m03:09:11.780855 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:09:11.781939 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.7354183, "process_in_blocks": "0", "process_kernel_time": 0.430951, "process_mem_max_rss": "205080", "process_out_blocks": "2200", "process_user_time": 4.403289}
[0m03:09:11.782596 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:09:11.782484 after 6.74 seconds
[0m03:09:11.783050 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:09:11.783518 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:09:11.821722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73eff1c69250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efec8e6fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73efe0b58380>]}
[0m03:09:11.822312 [debug] [MainThread]: Flushing usage events
[0m03:09:12.780946 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:12:15.477068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79153715c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791536f93b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791536aecb00>]}


============================== 03:12:15.480466 | 53f8b932-b5b8-4649-98fe-63bdcab4eb10 ==============================
[0m03:12:15.480466 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:12:15.481232 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'no_print': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'introspect': 'True', 'target_path': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'quiet': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'use_colors': 'True', 'invocation_command': 'dbt run-operation Ai_Validate_Model --args {"model_name": "my_first_dbt_model"}', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'static_parser': 'True', 'version_check': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m03:12:16.039148 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:12:16.039815 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:12:16.040426 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:12:16.244443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53f8b932-b5b8-4649-98fe-63bdcab4eb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152bdf7a10>]}
[0m03:12:16.315381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '53f8b932-b5b8-4649-98fe-63bdcab4eb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152e0b7530>]}
[0m03:12:16.316418 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:12:16.486463 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:12:16.594976 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
[0m03:12:16.595735 [debug] [MainThread]: Partial parsing: added file: Ai_Cortex://models/example/fixed.sql
[0m03:12:16.596387 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m03:12:16.596951 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/sample_@.sql
[0m03:12:16.935327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53f8b932-b5b8-4649-98fe-63bdcab4eb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152b214290>]}
[0m03:12:17.007795 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:12:17.009681 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:12:17.019884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53f8b932-b5b8-4649-98fe-63bdcab4eb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152b0952b0>]}
[0m03:12:17.020501 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:12:17.021009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53f8b932-b5b8-4649-98fe-63bdcab4eb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152b2c55b0>]}
[0m03:12:17.021741 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Validate_Model'
[0m03:12:17.027031 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Validate_Model
[0m03:12:17.027600 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m03:12:17.028060 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:12:17.847037 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  macro 'dbt_macro__Ai_Validate_Model' takes no keyword argument 'model_name'
[0m03:12:17.849947 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'dbt_macro__Ai_Validate_Model' takes no keyword argument 'model_name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  macro 'dbt_macro__Ai_Validate_Model' takes no keyword argument 'model_name'

[0m03:12:17.857245 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:12:17.858346 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 2.44488, "process_in_blocks": "0", "process_kernel_time": 0.407348, "process_mem_max_rss": "201456", "process_out_blocks": "2200", "process_user_time": 4.350364}
[0m03:12:17.858971 [debug] [MainThread]: Command `dbt run-operation` failed at 03:12:17.858857 after 2.45 seconds
[0m03:12:17.859485 [debug] [MainThread]: Connection 'macro_Ai_Validate_Model' was left open.
[0m03:12:17.859947 [debug] [MainThread]: On macro_Ai_Validate_Model: Close
[0m03:12:17.899875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791536db03b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152b2176b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79152b216630>]}
[0m03:12:17.900601 [debug] [MainThread]: Flushing usage events
[0m03:12:18.913557 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:12:22.511842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71096d1cf560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71096cec1e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71096dc955b0>]}


============================== 03:12:22.515210 | 2cd655ac-4147-404f-bed0-a4e4f1431190 ==============================
[0m03:12:22.515210 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:12:22.515919 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'printer_width': '80', 'invocation_command': 'dbt run-operation Ai_Validate_Model --args {"model_name": "my_first_dbt_model"}', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'fail_fast': 'False', 'version_check': 'True', 'target_path': 'None', 'debug': 'False', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'use_colors': 'True', 'static_parser': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'no_print': 'None'}
[0m03:12:23.071100 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:12:23.071767 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:12:23.072355 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:12:23.346012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2cd655ac-4147-404f-bed0-a4e4f1431190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710961000f20>]}
[0m03:12:23.416403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2cd655ac-4147-404f-bed0-a4e4f1431190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71096187d520>]}
[0m03:12:23.417379 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:12:23.615544 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:12:23.723266 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:12:23.723807 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:12:23.765297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2cd655ac-4147-404f-bed0-a4e4f1431190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710960e15dc0>]}
[0m03:12:23.846274 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:12:23.848159 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:12:23.858667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2cd655ac-4147-404f-bed0-a4e4f1431190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710960cdccb0>]}
[0m03:12:23.859269 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:12:23.859784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cd655ac-4147-404f-bed0-a4e4f1431190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71096139c680>]}
[0m03:12:23.860512 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Validate_Model'
[0m03:12:23.865532 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro Ai_Validate_Model
[0m03:12:23.866010 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m03:12:23.866482 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:12:24.023528 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  macro 'dbt_macro__Ai_Validate_Model' takes no keyword argument 'model_name'
[0m03:12:24.025354 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 418, in exception_handler
    yield
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jinja2/runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'dbt_macro__Ai_Validate_Model' takes no keyword argument 'model_name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1310, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 393, in call_macro
    with self.exception_handler():
  File "/usr/local/python/3.12.1/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 420, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt_common.exceptions.macros.CaughtMacroErrorWithNodeError: Compilation Error
  macro 'dbt_macro__Ai_Validate_Model' takes no keyword argument 'model_name'

[0m03:12:24.034697 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:12:24.035777 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.5851781, "process_in_blocks": "0", "process_kernel_time": 0.443102, "process_mem_max_rss": "197384", "process_out_blocks": "1120", "process_user_time": 4.056628}
[0m03:12:24.036430 [debug] [MainThread]: Command `dbt run-operation` failed at 03:12:24.036312 after 1.59 seconds
[0m03:12:24.036907 [debug] [MainThread]: Connection 'macro_Ai_Validate_Model' was left open.
[0m03:12:24.037390 [debug] [MainThread]: On macro_Ai_Validate_Model: Close
[0m03:12:24.078940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71096c9d3e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710960cdc230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7109612eda30>]}
[0m03:12:24.079523 [debug] [MainThread]: Flushing usage events
[0m03:12:25.030196 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:12:42.420907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a555e412e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a555be75f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a556379ee0>]}


============================== 03:12:42.426043 | e8c9cb0e-35a0-46fd-821b-6939f07890f1 ==============================
[0m03:12:42.426043 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:12:42.427423 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'printer_width': '80', 'invocation_command': 'dbt run-operation Ai_debug --args {"model_name": "my_first_dbt_model"}', 'use_experimental_parser': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'version_check': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'log_format': 'default', 'quiet': 'False', 'empty': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'target_path': 'None', 'use_colors': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False'}
[0m03:12:42.994065 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:12:42.994721 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:12:42.995288 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:12:43.195172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8c9cb0e-35a0-46fd-821b-6939f07890f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54a64c1a0>]}
[0m03:12:43.265239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8c9cb0e-35a0-46fd-821b-6939f07890f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54a64c290>]}
[0m03:12:43.266269 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:12:43.480351 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:12:43.592907 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:12:43.593473 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:12:43.634522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8c9cb0e-35a0-46fd-821b-6939f07890f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54a53e2a0>]}
[0m03:12:43.711696 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:12:43.713612 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:12:43.723889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8c9cb0e-35a0-46fd-821b-6939f07890f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54a2c8ef0>]}
[0m03:12:43.724494 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:12:43.724996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c9cb0e-35a0-46fd-821b-6939f07890f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54a187e00>]}
[0m03:12:43.725711 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_debug'
[0m03:12:43.726373 [error] [MainThread]: Encountered an error while running operation: Runtime Error
  dbt could not find a macro with the name "Ai_debug" in any package
[0m03:12:43.727313 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1294, in execute_macro
    raise DbtRuntimeError(
dbt_common.exceptions.base.DbtRuntimeError: Runtime Error
  dbt could not find a macro with the name "Ai_debug" in any package

[0m03:12:43.727908 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt could not find a macro with the name 'Ai_debug' in any package. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m03:12:43.728956 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.3748161, "process_in_blocks": "0", "process_kernel_time": 0.418913, "process_mem_max_rss": "192008", "process_out_blocks": "1096", "process_user_time": 4.030922}
[0m03:12:43.729751 [debug] [MainThread]: Command `dbt run-operation` failed at 03:12:43.729640 after 1.38 seconds
[0m03:12:43.730223 [debug] [MainThread]: Connection 'macro_Ai_debug' was properly closed.
[0m03:12:43.730695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a55553b740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54cd62660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a54a0c7920>]}
[0m03:12:43.731202 [debug] [MainThread]: Flushing usage events
[0m03:12:44.669205 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:13:04.424431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24d0cae690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24d03fabd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24d03f9850>]}


============================== 03:13:04.427896 | ee5de634-400a-4785-8e3e-ba382bae9a2b ==============================
[0m03:13:04.427896 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:13:04.428658 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'warn_error': 'None', 'cache_selected_only': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'use_colors': 'True', 'debug': 'False', 'version_check': 'True', 'partial_parse': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'static_parser': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'introspect': 'True', 'log_format': 'default', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'target_path': 'None', 'fail_fast': 'False'}
[0m03:13:04.977932 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:13:04.978588 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:13:04.979095 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:13:05.182680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee5de634-400a-4785-8e3e-ba382bae9a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c4c0ce00>]}
[0m03:13:05.252492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee5de634-400a-4785-8e3e-ba382bae9a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c4df62a0>]}
[0m03:13:05.253507 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:13:05.434450 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:13:05.542414 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:13:05.542943 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:13:05.584392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee5de634-400a-4785-8e3e-ba382bae9a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c49dad50>]}
[0m03:13:05.661291 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:13:05.663161 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:13:05.673521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee5de634-400a-4785-8e3e-ba382bae9a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c47b5b20>]}
[0m03:13:05.674087 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:13:05.674650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee5de634-400a-4785-8e3e-ba382bae9a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c46f7fb0>]}
[0m03:13:05.675387 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:13:05.728759 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:13:05.729526 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:13:05.730155 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:13:10.621223 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.891 seconds
[0m03:13:10.623067 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:13:10.630317 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:13:10.631418 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.267986, "process_in_blocks": "0", "process_kernel_time": 0.406856, "process_mem_max_rss": "201852", "process_out_blocks": "1136", "process_user_time": 4.147511}
[0m03:13:10.632048 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:13:10.631933 after 6.27 seconds
[0m03:13:10.632576 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:13:10.633032 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:13:10.668047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24d094db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c4460b60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d24c4461940>]}
[0m03:13:10.668611 [debug] [MainThread]: Flushing usage events
[0m03:13:11.572016 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:13:51.264085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95d423ade0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95d3db20f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95d36c3dd0>]}


============================== 03:13:51.267552 | 1aef1586-7803-4132-8712-c4c381400584 ==============================
[0m03:13:51.267552 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:13:51.268354 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'debug': 'False', 'write_json': 'True', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'use_colors': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'warn_error': 'None', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'indirect_selection': 'eager', 'quiet': 'False', 'empty': 'None', 'no_print': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'partial_parse': 'True', 'fail_fast': 'False', 'target_path': 'None'}
[0m03:13:51.806347 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:13:51.806975 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:13:51.807525 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:13:52.008406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1aef1586-7803-4132-8712-c4c381400584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c866b7d0>]}
[0m03:13:52.079312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1aef1586-7803-4132-8712-c4c381400584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c98e8ec0>]}
[0m03:13:52.080274 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:13:52.255510 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:13:52.362704 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:13:52.363442 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/example/fixed.sql
[0m03:13:52.649513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1aef1586-7803-4132-8712-c4c381400584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c8779850>]}
[0m03:13:52.735157 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:13:52.737224 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:13:52.747805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1aef1586-7803-4132-8712-c4c381400584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c8380ce0>]}
[0m03:13:52.748450 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:13:52.749016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aef1586-7803-4132-8712-c4c381400584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c8778ce0>]}
[0m03:13:52.749760 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:13:52.801511 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:13:52.802256 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:13:52.802917 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:13:57.520491 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.718 seconds
[0m03:13:57.522324 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:13:57.529589 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:13:57.530668 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.3270264, "process_in_blocks": "0", "process_kernel_time": 0.458714, "process_mem_max_rss": "205176", "process_out_blocks": "2208", "process_user_time": 4.398341}
[0m03:13:57.531299 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:13:57.531183 after 6.33 seconds
[0m03:13:57.531759 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:13:57.532216 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:13:57.566176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95d4584770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c8318f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c95c7c3a660>]}
[0m03:13:57.566728 [debug] [MainThread]: Flushing usage events
[0m03:13:58.541896 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:14:27.728388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f76462990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f75de3560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f77d40a70>]}


============================== 03:14:27.732877 | 1b32b390-c97f-424b-97ee-b8d45e5d98cd ==============================
[0m03:14:27.732877 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:14:27.733631 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'version_check': 'True', 'partial_parse': 'True', 'log_cache_events': 'False', 'debug': 'False', 'invocation_command': 'dbt run-operation Ai_debug --args {"model_name": "my_first_dbt_model"}', 'warn_error': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'quiet': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'empty': 'None', 'target_path': 'None', 'fail_fast': 'False', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'no_print': 'None', 'log_format': 'default'}
[0m03:14:28.276340 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:14:28.277021 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:14:28.277601 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:14:28.478232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1b32b390-c97f-424b-97ee-b8d45e5d98cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f6a4441d0>]}
[0m03:14:28.547630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1b32b390-c97f-424b-97ee-b8d45e5d98cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f6ad06e70>]}
[0m03:14:28.548580 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:14:28.752363 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:14:28.869164 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:14:28.869940 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://models/example/fixed.sql
[0m03:14:29.207255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b32b390-c97f-424b-97ee-b8d45e5d98cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f69e46e40>]}
[0m03:14:29.280239 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:14:29.282143 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:14:29.292302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1b32b390-c97f-424b-97ee-b8d45e5d98cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f69e47b30>]}
[0m03:14:29.292905 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:14:29.293451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b32b390-c97f-424b-97ee-b8d45e5d98cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f69e496d0>]}
[0m03:14:29.294181 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_debug'
[0m03:14:29.294820 [error] [MainThread]: Encountered an error while running operation: Runtime Error
  dbt could not find a macro with the name "Ai_debug" in any package
[0m03:14:29.295695 [debug] [MainThread]: Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1294, in execute_macro
    raise DbtRuntimeError(
dbt_common.exceptions.base.DbtRuntimeError: Runtime Error
  dbt could not find a macro with the name "Ai_debug" in any package

[0m03:14:29.296299 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt could not find a macro with the name 'Ai_debug' in any package. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m03:14:29.297372 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.6303179, "process_in_blocks": "0", "process_kernel_time": 0.440642, "process_mem_max_rss": "194616", "process_out_blocks": "2176", "process_user_time": 4.099372}
[0m03:14:29.298143 [debug] [MainThread]: Command `dbt run-operation` failed at 03:14:29.298004 after 1.63 seconds
[0m03:14:29.298617 [debug] [MainThread]: Connection 'macro_Ai_debug' was properly closed.
[0m03:14:29.299090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f774a30e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f69e49b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x749f69e48fb0>]}
[0m03:14:29.299609 [debug] [MainThread]: Flushing usage events
[0m03:14:30.271019 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:14:43.547989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9bcbd820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9b7597f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9c217b00>]}


============================== 03:14:43.551428 | 308a884b-f8fb-480a-b18a-f7ce29f21f2f ==============================
[0m03:14:43.551428 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:14:43.552177 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'printer_width': '80', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'empty': 'None', 'introspect': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'fail_fast': 'False', 'warn_error': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'no_print': 'None', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_format': 'default', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'debug': 'False', 'version_check': 'True'}
[0m03:14:44.217384 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:14:44.218019 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:14:44.218603 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:14:44.419257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '308a884b-f8fb-480a-b18a-f7ce29f21f2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9da7cc80>]}
[0m03:14:44.504330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '308a884b-f8fb-480a-b18a-f7ce29f21f2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9bc60bc0>]}
[0m03:14:44.505332 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:14:44.677898 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:14:44.823371 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:14:44.823889 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:14:44.865818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '308a884b-f8fb-480a-b18a-f7ce29f21f2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc90321e80>]}
[0m03:14:44.940191 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:14:44.942068 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:14:44.952393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '308a884b-f8fb-480a-b18a-f7ce29f21f2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9002fef0>]}
[0m03:14:44.952960 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:14:44.953500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '308a884b-f8fb-480a-b18a-f7ce29f21f2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc907ab920>]}
[0m03:14:44.954207 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:14:45.024900 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:14:45.026452 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:14:45.027981 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:14:50.903048 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.875 seconds
[0m03:14:50.906394 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:14:50.913625 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:14:50.914704 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 7.427213, "process_in_blocks": "0", "process_kernel_time": 0.436263, "process_mem_max_rss": "201804", "process_out_blocks": "1128", "process_user_time": 4.084377}
[0m03:14:50.915339 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:14:50.915221 after 7.43 seconds
[0m03:14:50.915812 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:14:50.916302 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:14:50.955303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9b7e3500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc9002f050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70bc90549370>]}
[0m03:14:50.955878 [debug] [MainThread]: Flushing usage events
[0m03:14:52.065817 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:19:07.575092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d0c39b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d0df966f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d0be0d790>]}


============================== 03:19:07.578657 | c715c385-7c96-4af8-858a-af7181cfce51 ==============================
[0m03:19:07.578657 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:19:07.579533 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'introspect': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'target_path': 'None', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/'}
[0m03:19:08.251262 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:19:08.252099 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:19:08.253181 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:19:08.472648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c715c385-7c96-4af8-858a-af7181cfce51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d00766180>]}
[0m03:19:08.544937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c715c385-7c96-4af8-858a-af7181cfce51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d0dbc7e00>]}
[0m03:19:08.545970 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:19:08.733239 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:19:08.846218 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:19:08.847105 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m03:19:08.855409 [error] [MainThread]: Encountered an error:
Compilation Error
  expected token ',', got 'error_reason'
    line 106
      {{ print('Fix Reason:'error_reason) }}
[0m03:19:08.856643 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.342396, "process_in_blocks": "0", "process_kernel_time": 0.413234, "process_mem_max_rss": "191396", "process_out_blocks": "16", "process_user_time": 3.836326}
[0m03:19:08.857451 [debug] [MainThread]: Command `dbt run-operation` failed at 03:19:08.857331 after 1.34 seconds
[0m03:19:08.857972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d0b759be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d0070ba40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d7d003947a0>]}
[0m03:19:08.858504 [debug] [MainThread]: Flushing usage events
[0m03:19:09.913746 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:19:57.149071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b646892a330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b646ab71dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b646892b950>]}


============================== 03:19:57.154456 | 3ab418e8-17a7-4287-a72b-9bfd3f9a188a ==============================
[0m03:19:57.154456 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:19:57.155264 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'target_path': 'None', 'partial_parse': 'True', 'log_format': 'default', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'introspect': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'quiet': 'False', 'empty': 'None', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'log_cache_events': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'static_parser': 'True'}
[0m03:19:57.681470 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:19:57.682154 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:19:57.682654 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:19:57.914736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ab418e8-17a7-4287-a72b-9bfd3f9a188a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6468080f20>]}
[0m03:19:57.985666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3ab418e8-17a7-4287-a72b-9bfd3f9a188a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b645d6f3da0>]}
[0m03:19:57.986608 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:19:58.160090 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:19:58.265773 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:19:58.266614 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m03:19:58.273902 [error] [MainThread]: Encountered an error:
Compilation Error
  expected token ',', got 'error_reason'
    line 110
      {{ print('Fix Reason:'error_reason) }}
[0m03:19:58.275058 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 1.1972904, "process_in_blocks": "0", "process_kernel_time": 0.39266, "process_mem_max_rss": "191476", "process_out_blocks": "16", "process_user_time": 3.799041}
[0m03:19:58.275844 [debug] [MainThread]: Command `dbt run-operation` failed at 03:19:58.275731 after 1.20 seconds
[0m03:19:58.276382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6469c5f5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b64673640e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b645da27830>]}
[0m03:19:58.276887 [debug] [MainThread]: Flushing usage events
[0m03:19:59.254333 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:20:11.746920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x763713c3e4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x763712beb170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7637151c4ef0>]}


============================== 03:20:11.750280 | fdd07f36-7158-4b29-8bfc-0e9bf80f8e6c ==============================
[0m03:20:11.750280 [info ] [MainThread]: Running with dbt=1.10.15
[0m03:20:11.751043 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'no_print': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'introspect': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/logs', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake/Ai_Cortex/', 'version_check': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'partial_parse': 'True', 'quiet': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}'}
[0m03:20:12.317585 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m03:20:12.319000 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m03:20:12.319952 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m03:20:12.545200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fdd07f36-7158-4b29-8bfc-0e9bf80f8e6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x763707f639b0>]}
[0m03:20:12.617473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fdd07f36-7158-4b29-8bfc-0e9bf80f8e6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x763707e0a8a0>]}
[0m03:20:12.618395 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m03:20:12.795417 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m03:20:12.904358 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:20:12.905192 [debug] [MainThread]: Partial parsing: updated file: Ai_Cortex://macros/Prompt/Ai_validate.sql
[0m03:20:13.018870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fdd07f36-7158-4b29-8bfc-0e9bf80f8e6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x763707b394f0>]}
[0m03:20:13.108316 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/manifest.json
[0m03:20:13.110260 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/semantic_manifest.json
[0m03:20:13.120350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fdd07f36-7158-4b29-8bfc-0e9bf80f8e6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76370778cb00>]}
[0m03:20:13.120921 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m03:20:13.121511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fdd07f36-7158-4b29-8bfc-0e9bf80f8e6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76371319e450>]}
[0m03:20:13.122237 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m03:20:13.187242 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m03:20:13.187975 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m03:20:13.188589 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:20:17.938543 [debug] [MainThread]: SQL status: SUCCESS 1 in 4.750 seconds
[0m03:20:17.940348 [info ] [MainThread]: Fix Reason:"Removed extra comma after UNION ALL"
[0m03:20:17.940940 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m03:20:17.949213 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/Ai_Cortex/target/run_results.json
[0m03:20:17.950320 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 6.2636814, "process_in_blocks": "0", "process_kernel_time": 0.454385, "process_mem_max_rss": "202164", "process_out_blocks": "2192", "process_user_time": 4.129237}
[0m03:20:17.950940 [debug] [MainThread]: Command `dbt run-operation` succeeded at 03:20:17.950818 after 6.26 seconds
[0m03:20:17.951445 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m03:20:17.951904 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m03:20:17.989776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7637128ec800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7637076dfe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7637073fc470>]}
[0m03:20:17.990382 [debug] [MainThread]: Flushing usage events
[0m03:20:19.063749 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:22.737731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71852e323c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x718530aad0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71852f29ba10>]}


============================== 18:38:22.855840 | d1ddbc7d-dc0e-4c25-9e8f-f58834f93d93 ==============================
[0m18:38:22.855840 [info ] [MainThread]: Running with dbt=1.10.15
[0m18:38:22.856886 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'log_path': '/workspaces/AI_Cortex_Snowflake/logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'printer_width': '80', 'empty': 'None', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'target_path': 'None', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'fail_fast': 'False', 'use_colors': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'no_print': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:38:22.957622 [info ] [MainThread]: dbt version: 1.10.15
[0m18:38:22.959083 [info ] [MainThread]: python version: 3.12.1
[0m18:38:22.959940 [info ] [MainThread]: python path: /usr/local/python/3.12.1/bin/python3
[0m18:38:22.960796 [info ] [MainThread]: os info: Linux-6.8.0-1030-azure-x86_64-with-glibc2.39
[0m18:38:30.369246 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m18:38:30.369923 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m18:38:30.370461 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m18:38:30.440459 [info ] [MainThread]: Using profiles dir at /workspaces/AI_Cortex_Snowflake
[0m18:38:30.441150 [info ] [MainThread]: Using profiles.yml file at /workspaces/AI_Cortex_Snowflake/profiles.yml
[0m18:38:30.441718 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/AI_Cortex_Snowflake/dbt_project.yml
[0m18:38:30.442812 [info ] [MainThread]: adapter type: snowflake
[0m18:38:30.443332 [info ] [MainThread]: adapter version: 1.10.3
[0m18:38:30.558768 [info ] [MainThread]: Configuration:
[0m18:38:30.559470 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:38:30.560048 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:38:30.560576 [info ] [MainThread]: Required dependencies:
[0m18:38:30.561150 [debug] [MainThread]: Executing "git --help"
[0m18:38:30.563637 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:38:30.564249 [debug] [MainThread]: STDERR: "b''"
[0m18:38:30.564784 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:38:30.565340 [info ] [MainThread]: Connection:
[0m18:38:30.566060 [info ] [MainThread]:   account: GXUGAIL-QU64760
[0m18:38:30.566783 [info ] [MainThread]:   user: saravanapandi
[0m18:38:30.567516 [info ] [MainThread]:   database: ai_cortex
[0m18:38:30.568220 [info ] [MainThread]:   warehouse: compute_wh
[0m18:38:30.568778 [info ] [MainThread]:   role: accountadmin
[0m18:38:30.569315 [info ] [MainThread]:   schema: public
[0m18:38:30.570065 [info ] [MainThread]:   authenticator: None
[0m18:38:30.570821 [info ] [MainThread]:   oauth_client_id: None
[0m18:38:30.571561 [info ] [MainThread]:   query_tag: None
[0m18:38:30.572283 [info ] [MainThread]:   client_session_keep_alive: False
[0m18:38:30.573016 [info ] [MainThread]:   host: None
[0m18:38:30.573729 [info ] [MainThread]:   port: None
[0m18:38:30.574392 [info ] [MainThread]:   proxy_host: None
[0m18:38:30.575095 [info ] [MainThread]:   proxy_port: None
[0m18:38:30.575623 [info ] [MainThread]:   protocol: None
[0m18:38:30.576237 [info ] [MainThread]:   connect_retries: 1
[0m18:38:30.576780 [info ] [MainThread]:   connect_timeout: None
[0m18:38:30.577357 [info ] [MainThread]:   retry_on_database_errors: False
[0m18:38:30.578084 [info ] [MainThread]:   retry_all: False
[0m18:38:30.578808 [info ] [MainThread]:   insecure_mode: False
[0m18:38:30.579503 [info ] [MainThread]:   reuse_connections: True
[0m18:38:30.580280 [info ] [MainThread]:   s3_stage_vpce_dns_name: None
[0m18:38:30.581027 [info ] [MainThread]:   platform_detection_timeout_seconds: 0.0
[0m18:38:30.581953 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m18:38:30.796182 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m18:38:31.116326 [debug] [MainThread]: Using snowflake connection "debug"
[0m18:38:31.116928 [debug] [MainThread]: On debug: select 1 as id
[0m18:38:31.117400 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:38:32.403910 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.286 seconds
[0m18:38:32.406388 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:38:32.407696 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:38:32.410910 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 9.734059, "process_in_blocks": "221400", "process_kernel_time": 0.679661, "process_mem_max_rss": "197028", "process_out_blocks": "40", "process_user_time": 3.841433}
[0m18:38:32.413382 [debug] [MainThread]: Command `dbt debug` succeeded at 18:38:32.413222 after 9.74 seconds
[0m18:38:32.414601 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:38:32.415332 [debug] [MainThread]: On debug: Close
[0m18:38:32.454420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7185231399d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71852347e7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x718522dccbc0>]}
[0m18:38:32.455412 [debug] [MainThread]: Flushing usage events
[0m18:38:33.684805 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:39:33.976437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c332ed5070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c33471fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c33256a480>]}


============================== 18:39:33.979755 | 4f092c5f-fae7-4fd0-8f13-4f4774ddeb4b ==============================
[0m18:39:33.979755 [info ] [MainThread]: Running with dbt=1.10.15
[0m18:39:33.980537 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'write_json': 'True', 'target_path': 'None', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'introspect': 'True', 'profiles_dir': '/workspaces/AI_Cortex_Snowflake', 'no_print': 'None', 'indirect_selection': 'eager', 'log_path': '/workspaces/AI_Cortex_Snowflake/logs', 'cache_selected_only': 'False', 'invocation_command': 'dbt run-operation Ai_Debug --args {"model_name": "my_first_dbt_model"}', 'debug': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True'}
[0m18:39:34.535437 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m18:39:34.536173 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m18:39:34.536730 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m18:39:34.787934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4f092c5f-fae7-4fd0-8f13-4f4774ddeb4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c326d21b80>]}
[0m18:39:34.868714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4f092c5f-fae7-4fd0-8f13-4f4774ddeb4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c326dd86b0>]}
[0m18:39:34.870183 [info ] [MainThread]: Registered adapter: snowflake=1.10.3
[0m18:39:35.080986 [debug] [MainThread]: checksum: 14a228079bd6df63ba81633f9a3cf44ecfaa31056ac397c602753ec895dbf885, vars: {}, profile: , target: , version: 1.10.15
[0m18:39:35.331355 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:39:35.331918 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:39:35.374307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f092c5f-fae7-4fd0-8f13-4f4774ddeb4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c326da7f50>]}
[0m18:39:35.448394 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/AI_Cortex_Snowflake/target/manifest.json
[0m18:39:35.450746 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/AI_Cortex_Snowflake/target/semantic_manifest.json
[0m18:39:35.461127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f092c5f-fae7-4fd0-8f13-4f4774ddeb4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c32691ff80>]}
[0m18:39:35.461701 [info ] [MainThread]: Found 5 models, 4 data tests, 508 macros
[0m18:39:35.462275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f092c5f-fae7-4fd0-8f13-4f4774ddeb4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c32690e0f0>]}
[0m18:39:35.462965 [debug] [MainThread]: Acquiring new snowflake connection 'macro_Ai_Debug'
[0m18:39:35.517622 [debug] [MainThread]: Using snowflake connection "macro_Ai_Debug"
[0m18:39:35.518349 [debug] [MainThread]: On macro_Ai_Debug: with main as (
      SELECT AI_COMPLETE(
        MODEL => 'claude-3-5-sonnet',
        PROMPT => 
$$
You are a Snowflake dbt SQL (Jinja-SQL) validator + auto-corrector.

Input:
- The input is a full dbt model file that may contain:
  * Jinja expressions: {{ ... }}
  * Jinja control blocks: {% ... %}
  * Jinja comments: 
  * dbt config blocks like: {{ config(materialized="table") }}
  * Standard SQL (CTEs, SELECT, INSERT, etc.)
  * Line / block comments (--) and (/* ... */)

Your job:
- Validate and, when safe, auto-correct ONLY the Snowflake SQL parts.
- Preserve all Jinja and dbt-specific constructs exactly as given.

Output format (must follow exactly):
- Output EXACTLY ONE compact JSON object, one line, no newlines, no surrounding quotes, no escaping:
  {"sql":"<correct_or_original_dbt_code>","error_reason":"<empty_or_reason>","able_correct":<0_or_1>}

Jinja / dbt preservation rules:
- Do NOT change, remove, or reorder anything inside:
  * {{ ... }}
  * {% ... %}
  * 
- Do NOT modify dbt macros, ref(), source(), config(), variables, or any Jinja expression.
- Keep comments and commented-out lines (starting with -- or /* */) exactly as in the input.
- If there is a top-level {{ config(...) }} block or any other Jinja at the beginning/end, keep it in the same position.

Canonicalization rules for SQL PARTS ONLY:
- SQL keywords MUST be uppercase (SELECT, FROM, WHERE, INSERT, VALUES, JOIN, ON, GROUP BY, ORDER BY, LIMIT, WITH, AS, UNION ALL, etc.).
- Use single spaces between SQL tokens.
- Ensure the final SQL statement ends with a single semicolon (;) if appropriate for Snowflake.
- Do NOT change column names, table names, literals, function names, or business logic except necessary token insertion/reordering to make the statement syntactically valid.
- Do NOT add semicolons inside Jinja blocks; only at statement boundaries in pure SQL.

Decision rules:
- If the SQL (ignoring Jinja blocks) is already valid Snowflake SQL:
  * Return the SAME dbt code (Jinja + SQL) but with SQL keywords canonicalized as above.
  * Set "error_reason":"" and "able_correct":1.

- If the SQL is invalid but can be fixed by a SINGLE, unambiguous change (examples):
  * Missing FROM between SELECT clause and table name.
  * Missing comma between selected columns.
  * Missing semicolon at the end of the statement.
  * Simple token reordering like "SELECT * table FROM" -> "SELECT * FROM table".
  Then:
  * Return the corrected dbt code (Jinja preserved, SQL canonicalized).
  * Provide a concise "error_reason" describing the fix.
  * Set "able_correct":1.

- If the SQL is invalid and cannot be safely fixed because essential info is missing or ambiguous:
  * Examples: missing table name after FROM, missing target table for INSERT, incomplete JOIN with no ON clause and no obvious fix, etc.
  * Return the ORIGINAL dbt code EXACTLY as provided.
  * Provide a short "error_reason" explaining why it cannot be safely corrected.
  * Set "able_correct":0.
  * Do NOT invent table or column names or dbt objects.

Forbidden:
- Do NOT return pretty-printed JSON.
- Do NOT include extra explanation text outside the JSON.
- Do NOT invent identifiers (table/column names, dbt refs, sources, macros).
- Do NOT perform multi-step or risky semantic changes.

Example behavior with dbt code (illustrative, do not output this example).

Now validate and correct this dbt model code (apply only the above rules):
 /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

with source_data as (

    select 1 as id
    union all,,
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
$$

      ) AS result)
    select parse_json(result):sql as sql,parse_json(result):error_reason, parse_json(result):able_correct  from main
/* {"app": "dbt", "dbt_version": "1.10.15", "profile_name": "Ai_Cortex", "target_name": "dev", "connection_name": "macro_Ai_Debug"} */;
[0m18:39:35.518975 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:39:41.978633 [debug] [MainThread]: SQL status: SUCCESS 1 in 6.460 seconds
[0m18:39:41.980754 [info ] [MainThread]: Fix Reason:"Removed extra comma between UNION ALL statements"
[0m18:39:41.981361 [info ] [MainThread]: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

{{ config(materialized='table') }}

WITH source_data AS (

    SELECT 1 AS id
    UNION ALL
    SELECT null AS id

)

SELECT *
FROM source_data;

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null

[0m18:39:41.989959 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /workspaces/AI_Cortex_Snowflake/target/run_results.json
[0m18:39:41.991049 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 8.075256, "process_in_blocks": "5168", "process_kernel_time": 0.462441, "process_mem_max_rss": "202160", "process_out_blocks": "1136", "process_user_time": 4.093896}
[0m18:39:41.991695 [debug] [MainThread]: Command `dbt run-operation` succeeded at 18:39:41.991545 after 8.08 seconds
[0m18:39:41.992160 [debug] [MainThread]: Connection 'macro_Ai_Debug' was left open.
[0m18:39:41.992605 [debug] [MainThread]: On macro_Ai_Debug: Close
[0m18:39:42.032052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c331d42f30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c32691f800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72c326660e90>]}
[0m18:39:42.032679 [debug] [MainThread]: Flushing usage events
[0m18:39:43.187991 [debug] [MainThread]: An error was encountered while trying to flush usage events
